import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { logger } from '../utils/logger.js';
import { MCPManager } from './mcpManager.js';
import { MCPToolAdapter } from './mcpToolAdapter.js';
import { MCPAuthService } from './mcpAuthService.js';
import { getTaskService } from './taskService.js';
import { taskExecutorDao } from '../dao/taskExecutorDao.js';
import { messageDao } from '../dao/messageDao.js';
import { conversationDao } from '../dao/conversationDao.js';
import { MessageType, MessageIntent, MessageStepType } from '../models/conversation.js';

/**
 * å·¥ä½œæµæ­¥éª¤ - åŸºäºTaskAnalysisServiceæ„å»ºçš„ç»“æ„
 */
export interface WorkflowStep {
  step: number;
  mcp: string;
  action: string;
  input?: any;
  // å¢å¼ºå­—æ®µ
  status?: 'pending' | 'executing' | 'completed' | 'failed';
  result?: any;
  error?: string;
  attempts?: number;
  maxRetries?: number;
}

/**
 * å¢å¼ºçš„å·¥ä½œæµçŠ¶æ€
 */
export interface EnhancedWorkflowState {
  taskId: string;
  originalQuery: string;
  workflow: WorkflowStep[];
  currentStepIndex: number;
  executionHistory: Array<{
    stepNumber: number;
    mcpName: string;
    action: string;
    success: boolean;
    result?: any;
    error?: string;
    timestamp: Date;
  }>;
  dataStore: Record<string, any>;
  isComplete: boolean;
  totalSteps: number;
  completedSteps: number;
  failedSteps: number;
}

/**
 * å¢å¼ºçš„æ™ºèƒ½Taskæ‰§è¡Œå¼•æ“
 * ä¸“æ³¨äºæ‰§è¡Œå·²æ„å»ºçš„MCPå·¥ä½œæµï¼Œç»“åˆAgentå¼•æ“çš„æ™ºèƒ½åŒ–ä¼˜åŠ¿
 */
export class EnhancedIntelligentTaskEngine {
  private llm: ChatOpenAI;
  private mcpManager: MCPManager;
  private mcpToolAdapter: MCPToolAdapter;
  private mcpAuthService: MCPAuthService;
  private taskService: any;

  constructor() {
    this.llm = new ChatOpenAI({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'gpt-4o',
      temperature: 0.1,
    });

    this.mcpManager = new MCPManager();
    this.mcpToolAdapter = new MCPToolAdapter(this.mcpManager);
    this.mcpAuthService = new MCPAuthService();
    this.taskService = getTaskService();
  }

  /**
   * å¢å¼ºçš„Taskæµå¼æ‰§è¡Œ - åŸºäºå·²æ„å»ºçš„å·¥ä½œæµ
   */
  async *executeWorkflowEnhanced(
    taskId: string,
    mcpWorkflow: any
  ): AsyncGenerator<{ event: string; data: any }, boolean, unknown> {
    
    // ğŸ”§ CRITICAL DEBUG: ç¡®è®¤è¿›å…¥Enhancedå¼•æ“
    logger.info(`ğŸš¨ ENHANCED ENGINE STARTED - Task: ${taskId}`);
    logger.info(`ğŸš€ Starting enhanced workflow execution [Task: ${taskId}]`);

    // ğŸ”§ éªŒè¯å·¥ä½œæµç»“æ„
    if (!mcpWorkflow || !mcpWorkflow.workflow || mcpWorkflow.workflow.length === 0) {
      yield {
        event: 'error',
        data: { 
          message: 'No valid workflow found. Please run task analysis first.',
          details: 'The task must be analyzed to generate a workflow before execution.'
        }
      };
      return false;
    }

    // ğŸ§  æ™ºèƒ½ä»»åŠ¡å¤æ‚åº¦åˆ†æ
    const task = await this.taskService.getTaskById(taskId);
    const taskQuery = task?.content || '';
    const taskComplexity = await this.analyzeTaskComplexity(taskQuery, mcpWorkflow.workflow.length);
    
    logger.info(`ğŸ¯ Task complexity analysis: ${taskComplexity.type} (${taskComplexity.recommendedObservation})`);

    // ğŸ”§ æ ¹æ®å¤æ‚åº¦è°ƒæ•´æ‰§è¡Œç­–ç•¥
    const shouldObserveEveryStep = taskComplexity.type !== 'simple_query';

    // ğŸ”§ å‘é€æ‰§è¡Œå¼€å§‹äº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œäº‹ä»¶åç§°
    yield {
      event: 'execution_start',
      data: {
        taskId,
        agentName: 'WorkflowEngine',
        taskComplexity: taskComplexity.type,
        observationStrategy: taskComplexity.recommendedObservation,
        timestamp: new Date().toISOString(),
        message: `Starting execution...`,
        mode: 'enhanced',
        workflowInfo: {
          totalSteps: mcpWorkflow.workflow.length,
          mcps: mcpWorkflow.mcps?.map((mcp: any) => mcp.name) || []
        }
      }
    };

    // ğŸ”§ åˆå§‹åŒ–å¢å¼ºçš„å·¥ä½œæµçŠ¶æ€
    const state: EnhancedWorkflowState = {
      taskId,
      originalQuery: '', // ä»taskè·å–
      workflow: mcpWorkflow.workflow.map((step: any, index: number) => ({
        ...step,
        status: 'pending',
        attempts: 0,
        maxRetries: 2
      })),
      currentStepIndex: 0,
      executionHistory: [],
      dataStore: {},
      isComplete: false,
      totalSteps: mcpWorkflow.workflow.length,
      completedSteps: 0,
      failedSteps: 0
    };

    try {
      // ğŸ”§ è·å–ä»»åŠ¡ä¿¡æ¯
      const task = await this.taskService.getTaskById(taskId);
      if (task) {
        state.originalQuery = task.content;
      }

      // ğŸ”§ å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
      await this.prepareWorkflowExecution(taskId, state, mcpWorkflow);

      // ğŸ”§ ç§»é™¤workflow_execution_startäº‹ä»¶ï¼Œç›´æ¥å¼€å§‹æ­¥éª¤æ‰§è¡Œ

      for (let i = 0; i < state.workflow.length; i++) {
        const currentStep = state.workflow[i];
        state.currentStepIndex = i;

        logger.info(`ğŸ§  Executing workflow step ${currentStep.step}: ${currentStep.mcp}.${currentStep.action}`);

        // ğŸ”§ é¢„å¤„ç†å‚æ•°ï¼šæ™ºèƒ½å‚æ•°å¤„ç†ï¼Œå¦‚æœinputä¸ºç©ºï¼Œå°è¯•ä»ä¸Šä¸‹æ–‡æ¨å¯¼
        let processedInput = currentStep.input || {};
        if (!currentStep.input && state.dataStore.lastResult) {
          processedInput = this.inferStepInputFromContext(currentStep, state);
        }

        // ğŸ”§ ç¡®å®šå·¥å…·ç±»å‹å’Œæ™ºèƒ½æè¿° - ä¸Agentå¼•æ“ä¸€è‡´
        const isLLMTool = currentStep.mcp === 'llm' || currentStep.mcp.toLowerCase().includes('llm');
        const toolType = isLLMTool ? 'llm' : 'mcp';
        const mcpName = isLLMTool ? null : currentStep.mcp;
        
        // ğŸ”§ é¢„å…ˆæ¨æ–­å®é™…å·¥å…·åç§°
        let actualToolName = currentStep.action;
        if (!isLLMTool) {
          const task = await this.taskService.getTaskById(state.taskId);
          if (task) {
            logger.info(`ğŸ” Inferring tool name for step ${currentStep.step}: ${currentStep.mcp}.${currentStep.action}`);
            actualToolName = await this.inferActualToolName(currentStep.mcp, currentStep.action, processedInput, task.userId);
            logger.info(`âœ… Tool name inference completed: ${actualToolName}`);
          }
        }

        // ğŸ”§ ç”Ÿæˆç®€å•çš„expectedOutputå’Œreasoningï¼ˆä½¿ç”¨å®é™…å·¥å…·åç§°ï¼‰
        const expectedOutput = isLLMTool 
          ? `AI analysis and processing for ${actualToolName}`
          : `Execute ${actualToolName} on ${currentStep.mcp}`;
        const reasoning = `Workflow step ${currentStep.step}`;

        // ğŸ”§ å‘é€æ­¥éª¤å¼€å§‹äº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œäº‹ä»¶åç§°
        const stepId = `workflow_step_${currentStep.step}_${Date.now()}`;
        yield {
          event: 'step_executing',
          data: {
            step: currentStep.step,
            mcpName: mcpName || currentStep.mcp,
            actionName: actualToolName,
            input: JSON.stringify(processedInput),
            agentName: 'WorkflowEngine',
            message: `WorkflowEngine is executing step ${currentStep.step}: ${actualToolName}`,
            // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„toolDetailsç»“æ„
            toolDetails: {
              toolType: toolType,
              toolName: actualToolName,
              mcpName: mcpName,
              args: processedInput,
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            }
          }
        };

        // ğŸ”§ æ‰§è¡Œå½“å‰æ­¥éª¤ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰- ä¼ é€’é¢„å¤„ç†çš„å‚æ•°å’Œå®é™…å·¥å…·åç§°
        logger.info(`ğŸ”„ Starting execution for step ${currentStep.step} with tool: ${actualToolName}`);
        const executionResult = await this.executeWorkflowStepWithRetry(currentStep, state, processedInput, actualToolName);
        logger.info(`ğŸ“‹ Execution result:`, {
          success: executionResult.success,
          hasResult: !!executionResult.result,
          resultSize: executionResult.result ? JSON.stringify(executionResult.result).length : 0,
          error: executionResult.error || 'none'
        });

        // ğŸ”§ CRITICAL: æ£€æŸ¥æ˜¯å¦åˆ°è¾¾äº†åç»­å¤„ç†é˜¶æ®µ
        logger.info(`ğŸ¯ REACHED POST-EXECUTION PROCESSING - Step ${currentStep.step}`);

        // ğŸ”§ è®°å½•æ‰§è¡Œå†å²
        const historyEntry = {
          stepNumber: currentStep.step,
          mcpName: currentStep.mcp,
          action: currentStep.action,
          success: executionResult.success,
          result: executionResult.result,
          error: executionResult.error,
          timestamp: new Date()
        };
        state.executionHistory.push(historyEntry);

        // ğŸ”§ é‡è¦è°ƒè¯•ï¼šæ£€æŸ¥executionResultçš„ç»“æ„
        logger.info(`ğŸ” CRITICAL DEBUG - executionResult:`, {
          success: executionResult.success,
          hasResult: !!executionResult.result,
          resultType: typeof executionResult.result,
          resultKeys: executionResult.result ? Object.keys(executionResult.result) : 'no result'
        });

        // ğŸ”§ å‘é€step_raw_resultäº‹ä»¶ï¼ˆæ–°å¢äº‹ä»¶ï¼‰
        if (executionResult.success && executionResult.result) {
          logger.info(`ğŸ¯ CRITICAL DEBUG - Conditions met, yielding step_raw_result`);
          
          yield {
            event: 'step_raw_result',
            data: {
              step: currentStep.step,
              success: true,
              result: executionResult.result,  // åŸå§‹MCPæ•°æ®ç»“æ„
              agentName: 'WorkflowEngine',
              executionDetails: {
                toolType: toolType,
                toolName: actualToolName,
                mcpName: mcpName,
                // ğŸ”§ ç§»é™¤rawResulté‡å¤ - æ•°æ®å·²åœ¨ä¸Šé¢çš„resultå­—æ®µä¸­
                args: executionResult.actualArgs || currentStep.input || {},
                expectedOutput: expectedOutput,
                timestamp: new Date().toISOString()
              }
            }
          };

          // ğŸ”§ å¼‚æ­¥ä¿å­˜åŸå§‹ç»“æœï¼Œé¿å…é˜»å¡æµå¼å“åº”
          this.saveStepRawResult(taskId, currentStep.step, currentStep, executionResult.result, executionResult.actualArgs, toolType, mcpName, expectedOutput, reasoning, actualToolName).catch(error => {
            logger.error(`Failed to save step raw result:`, error);
          });
        }

        // ğŸ”§ æµå¼æ ¼å¼åŒ–ç»“æœå¤„ç†ï¼ˆå‚è€ƒAgentå¼•æ“ï¼‰
        let formattedResult = '';
        if (executionResult.success && executionResult.result) {
          // ğŸ”§ æµå¼æ ¼å¼åŒ–ï¼šå…ˆå‘é€æµå¼æ ¼å¼åŒ–å—ï¼ˆä»…å¯¹MCPå·¥å…·ï¼‰
          if (toolType === 'mcp') {
            const formatGenerator = this.formatAndStreamTaskResult(
              executionResult.result,
              currentStep.mcp,
              actualToolName
            );

            // ğŸ”§ ä½¿ç”¨å‰ç«¯å¯¹åº”çš„äº‹ä»¶åç§°
            if (currentStep.step === state.totalSteps) {
              // æœ€åä¸€æ­¥ï¼šå‘é€step_startäº‹ä»¶ç„¶åä½¿ç”¨summary_chunkäº‹ä»¶
              yield {
                event: 'step_start',
                data: {
                  message: `Running ${mcpName || ''} - ${actualToolName || ''}`,
                  agentName: 'WorkflowEngine'
                }
              };
              
              for await (const chunk of formatGenerator) {
                yield {
                  event: 'summary_chunk',
                  data: {
                    content: chunk,
                    agentName: 'WorkflowEngine'
                  }
                };
              }
            } else {
              // ä¸­é—´æ­¥éª¤ï¼šæš‚æ—¶è·³è¿‡æµå¼è¾“å‡ºï¼Œåªä¿ç•™æœ€ç»ˆæ ¼å¼åŒ–ç»“æœ
            }
          }

          // ğŸ”§ ç”Ÿæˆå®Œæ•´çš„æ ¼å¼åŒ–ç»“æœç”¨äºå­˜å‚¨å’Œæœ€ç»ˆäº‹ä»¶
          formattedResult = await this.generateFormattedResult(
            executionResult.result,
            currentStep.mcp,
            actualToolName
          );

          // ğŸ”§ ç§»é™¤step_formatted_resultäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦

          // ğŸ”§ å¼‚æ­¥ä¿å­˜æ ¼å¼åŒ–ç»“æœï¼Œé¿å…é˜»å¡æµå¼å“åº”
          this.saveStepFormattedResult(taskId, currentStep.step, currentStep, formattedResult, executionResult.actualArgs, toolType, mcpName, expectedOutput, reasoning, actualToolName).catch(error => {
            logger.error(`Failed to save step formatted result:`, error);
          });

          // ğŸ”§ æ›´æ–°æ•°æ®å­˜å‚¨
          state.dataStore[`step_${currentStep.step}_result`] = executionResult.result;
          state.dataStore.lastResult = executionResult.result;
        }

        // ğŸ”§ æ›´æ–°æ­¥éª¤çŠ¶æ€
        if (executionResult.success) {
          currentStep.status = 'completed';
          state.completedSteps++;
          
          // ğŸ”§ å‘é€step_completeäº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œæ ¼å¼
          yield {
            event: 'step_complete',
            data: {
              step: currentStep.step,
              success: true,
              result: formattedResult || executionResult.result, // æ ¼å¼åŒ–ç»“æœä¾›å‰ç«¯æ˜¾ç¤º
              rawResult: executionResult.result, // ä¿ç•™åŸå§‹MCPç»“æœä¾›è°ƒè¯•
              // ğŸ”§ ä¿ç•™æ™ºèƒ½å¼•æ“çš„å¢å¼ºå­—æ®µ
              agentName: 'WorkflowEngine',
              message: `WorkflowEngine completed step ${currentStep.step} successfully`,
              progress: {
                completed: state.completedSteps,
                total: state.totalSteps,
                percentage: Math.round((state.completedSteps / state.totalSteps) * 100)
              }
            }
          };
        } else {
          currentStep.status = 'failed';
          state.failedSteps++;

          // ğŸ”§ å‘é€step_erroräº‹ä»¶ - ç®€åŒ–æ ¼å¼
          yield {
            event: 'step_error',
            data: {
              step: currentStep.step,
              error: executionResult.error,
              agentName: 'WorkflowEngine'
            }
          };
        }

        // ğŸ¯ ä¸Agentå¼•æ“ä¿æŒä¸€è‡´ï¼šä½¿ç”¨æ™ºèƒ½è§‚å¯Ÿé˜¶æ®µåˆ¤æ–­å®Œæˆ
        let shouldContinue = true;

        // ğŸ”§ æ‰§è¡ŒæˆåŠŸåè¿›è¡Œæ™ºèƒ½è§‚å¯Ÿåˆ¤æ–­ï¼ˆä¸Agentå¼•æ“ä¸€è‡´ï¼‰
        if (executionResult.success) {
          logger.info(`ğŸ” Task performing intelligent observation after step ${i + 1}`);
          
          const observationResult = await this.taskObservationPhase(state, taskComplexity);
          
          if (!observationResult.shouldContinue) {
            logger.info(`ğŸ¯ Task determined complete after intelligent observation`);
            shouldContinue = false;
            
            // å‘é€ä»»åŠ¡å®Œæˆäº‹ä»¶
            yield {
              event: 'task_observation_complete',
              data: {
                step: i + 1,
                message: 'Task determined complete by intelligent observation',
                reasoning: observationResult.newObjective || 'Task requirements fulfilled',
                taskComplete: true
              }
            };
          } else if (observationResult.newObjective) {
            logger.info(`ğŸ¯ Task next objective: ${observationResult.newObjective}`);
          }
        }

        // ğŸ”§ ç§»é™¤task_observationäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦
        
        // ğŸ”„ ç®€åŒ–åŠ¨æ€è§„åˆ’é€»è¾‘ï¼ˆä¿ç•™å·¥ä½œæµé€‚åº”èƒ½åŠ›ä½†å‡å°‘å¤æ‚åº¦ï¼‰
        let shouldAdaptWorkflow = false;
        
        // åªåœ¨å¤±è´¥æ—¶è€ƒè™‘å·¥ä½œæµé€‚åº”
        if (!executionResult.success && i < state.workflow.length - 2) {
          shouldAdaptWorkflow = await this.shouldAdaptWorkflow(state, currentStep);
        }
        
        if (shouldAdaptWorkflow) {
          logger.info(`ğŸ§  Initiating dynamic workflow adaptation...`);
          
          const currentContext = this.buildCurrentContext(state);
          const planningResult = await this.taskDynamicPlanningPhase(state, currentContext);
          
          if (planningResult.success && planningResult.adaptedSteps) {
            // ç”¨åŠ¨æ€è§„åˆ’çš„æ­¥éª¤æ›¿æ¢å‰©ä½™å·¥ä½œæµ
            const adaptedWorkflow = planningResult.adaptedSteps.map((adaptedStep, index) => ({
              ...adaptedStep,
              step: i + index + 1,
              status: 'pending' as const,
              attempts: 0,
              maxRetries: 2
            }));
            
            // æ›´æ–°å·¥ä½œæµï¼šä¿ç•™å·²å®Œæˆçš„æ­¥éª¤ï¼Œæ›¿æ¢å‰©ä½™æ­¥éª¤
            state.workflow = [
              ...state.workflow.slice(0, i + 1),
              ...adaptedWorkflow
            ];
            state.totalSteps = state.workflow.length;
            
            // ğŸ”§ ç§»é™¤workflow_adaptedäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦
            
            logger.info(`âœ… Workflow adapted: ${adaptedWorkflow.length} new steps planned`);
          }
        }
        
        // ğŸ¯ ç›´æ¥å®Œæˆæ£€æµ‹ï¼šå¦‚æœåˆ¤æ–­ä»»åŠ¡å·²å®Œæˆï¼Œç«‹å³é€€å‡º
        if (!shouldContinue) {
          logger.info(`ğŸ Task completion detected, stopping workflow execution`);
          break;
        }
      }

      // ğŸ”§ æ£€æŸ¥å®ŒæˆçŠ¶æ€
      state.isComplete = state.completedSteps > 0; // è‡³å°‘æœ‰ä¸€æ­¥æˆåŠŸå°±ç®—éƒ¨åˆ†å®Œæˆ

      // ğŸ”§ ç”Ÿæˆæœ€ç»ˆç»“æœ
      const finalResult = this.generateWorkflowFinalResult(state);
      const overallSuccess = state.completedSteps > 0;
      
      // ğŸ”§ å‘é€generating_summaryäº‹ä»¶
      yield {
        event: 'generating_summary',
        data: {
          message: 'Generating summary...',
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ å‘é€workflow_completeäº‹ä»¶
      yield {
        event: 'workflow_complete',
        data: {
          message: 'Workflow completed',
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ å‘é€task_completeäº‹ä»¶
      yield {
        event: 'task_complete',
        data: {
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ ä¿å­˜æœ€ç»ˆç»“æœ
      await this.saveWorkflowFinalResult(taskId, state, finalResult);

      return state.completedSteps > 0;

    } catch (error) {
      logger.error(`âŒ Enhanced workflow execution failed:`, error);
      
      yield {
        event: 'error',
        data: {
          message: 'Enhanced workflow execution failed',
          details: error instanceof Error ? error.message : String(error)
        }
      };

      return false;
    }
  }

  /**
   * å‡†å¤‡å·¥ä½œæµæ‰§è¡Œç¯å¢ƒ
   */
  private async prepareWorkflowExecution(taskId: string, state: EnhancedWorkflowState, mcpWorkflow: any): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (!task) {
        throw new Error('Task not found');
      }

      // ğŸ”§ ç¡®ä¿å·¥ä½œæµä¸­ç”¨åˆ°çš„MCPå·²è¿æ¥
      const requiredMCPs = [...new Set(state.workflow.map(step => step.mcp))];
      if (requiredMCPs.length > 0) {
        logger.info(`ğŸ“¡ Ensuring required MCPs are connected: ${requiredMCPs.join(', ')}`);
        await this.ensureWorkflowMCPsConnected(task.userId, taskId, requiredMCPs);
      }
    } catch (error) {
      logger.error('Failed to prepare workflow execution:', error);
      throw error;
    }
  }

  /**
   * ç¡®ä¿å·¥ä½œæµçš„MCPå·²è¿æ¥ - åŒæ­¥Agentå¼•æ“çš„å®Œæ•´æƒé™æ ¡éªŒé€»è¾‘
   */
  private async ensureWorkflowMCPsConnected(userId: string, taskId: string, mcpNames: string[]): Promise<void> {
    try {
      logger.info(`Ensuring MCP connections for workflow execution (User: ${userId}), required MCPs: ${mcpNames.join(', ')}`);

      // ğŸ”§ è·å–ä»»åŠ¡ä¿¡æ¯ä»¥è·å–å·¥ä½œæµMCPé…ç½®
      const task = await this.taskService.getTaskById(taskId);
      const mcpWorkflow = typeof task.mcpWorkflow === 'string' 
        ? JSON.parse(task.mcpWorkflow) 
        : task.mcpWorkflow;

      for (const mcpName of mcpNames) {
        try {
          logger.info(`ğŸ”— Ensuring MCP ${mcpName} is connected for workflow execution`);
          
          // æ£€æŸ¥MCPæ˜¯å¦å·²è¿æ¥
          const connectedMCPs = this.mcpManager.getConnectedMCPs(userId);
          const isConnected = connectedMCPs.some(mcp => mcp.name === mcpName);
          
          if (!isConnected) {
            logger.info(`MCP ${mcpName} not connected for user ${userId}, attempting to connect for workflow task...`);
            
            // ğŸ”§ è·å–MCPé…ç½®
            const { getPredefinedMCP } = await import('./predefinedMCPs.js');
            const mcpConfig = getPredefinedMCP(mcpName);
            
            if (!mcpConfig) {
              throw new Error(`MCP ${mcpName} configuration not found`);
            }

            // ğŸ”§ ä»å·¥ä½œæµä¸­æŸ¥æ‰¾MCPä¿¡æ¯ï¼ˆåŒæ­¥Agentå¼•æ“é€»è¾‘ï¼‰
            const mcpInfo = mcpWorkflow?.mcps?.find((mcp: any) => mcp.name === mcpName) || { name: mcpName, authRequired: mcpConfig.authRequired };

            let authenticatedMcpConfig = mcpConfig;

            // ğŸ”§ ä½¿ç”¨å·¥ä½œæµä¸­çš„authRequiredæ ‡è¯† - åŒæ­¥Agentå¼•æ“
            if (mcpInfo.authRequired) {
              // è·å–ç”¨æˆ·è®¤è¯ä¿¡æ¯
              const userAuth = await this.mcpAuthService.getUserMCPAuth(userId, mcpName);
              if (!userAuth || !userAuth.isVerified || !userAuth.authData) {
                throw new Error(`User authentication not found or not verified for MCP ${mcpName}. Please authenticate this MCP service first.`);
              }

              // åŠ¨æ€æ³¨å…¥è®¤è¯ä¿¡æ¯
              console.log(`\nğŸ”§ === MCP Auth Injection Debug (Enhanced Engine) ===`);
              console.log(`MCP Name: ${mcpName}`);
              console.log(`User ID: ${userId}`);
              console.log(`Task ID: ${taskId}`);
              console.log(`Auth Data Keys: ${Object.keys(userAuth.authData)}`);
              console.log(`Auth Params: ${JSON.stringify(mcpConfig.authParams, null, 2)}`);
              console.log(`Env Config: ${JSON.stringify(mcpConfig.env, null, 2)}`);
              
              const dynamicEnv = { ...mcpConfig.env };
              if (mcpConfig.env) {
                for (const [envKey, envValue] of Object.entries(mcpConfig.env)) {
                  console.log(`Checking env var: ${envKey} = "${envValue}"`);
                  
                  // ğŸ”§ æ”¹è¿›ï¼šæ£€æŸ¥ç”¨æˆ·è®¤è¯æ•°æ®ä¸­æ˜¯å¦æœ‰å¯¹åº”çš„é”®
                  let authValue = userAuth.authData[envKey];
                  
                  // ğŸ”§ å¦‚æœç›´æ¥é”®åä¸å­˜åœ¨ï¼Œå°è¯•ä»authParamsæ˜ å°„ä¸­æŸ¥æ‰¾
                  if (!authValue && mcpConfig.authParams && mcpConfig.authParams[envKey]) {
                    const authParamKey = mcpConfig.authParams[envKey];
                    authValue = userAuth.authData[authParamKey];
                    console.log(`ğŸ”§ Trying authParams mapping: ${envKey} -> ${authParamKey}, value: "${authValue}"`);
                  }
                  
                  if ((!envValue || envValue === '') && authValue) {
                    dynamicEnv[envKey] = authValue;
                    console.log(`âœ… Injected ${envKey} = "${authValue}"`);
                    logger.info(`Injected authentication for ${envKey} in MCP ${mcpName} for user ${userId}`);
                  } else {
                    console.log(`âŒ Not injecting ${envKey}: envValue="${envValue}", authValue: "${authValue}"`);
                  }
                }
              }

              // åˆ›å»ºå¸¦è®¤è¯ä¿¡æ¯çš„MCPé…ç½®
              authenticatedMcpConfig = {
                ...mcpConfig,
                env: dynamicEnv
              };
            } else {
              logger.info(`MCP ${mcpName} does not require authentication, using default configuration`);
            }

            // ğŸ”§ ä½¿ç”¨connectPredefinedæ–¹æ³•å®ç°å¤šç”¨æˆ·éš”ç¦»
            const connected = await this.mcpManager.connectPredefined(authenticatedMcpConfig, userId);
            if (!connected) {
              throw new Error(`Failed to connect to MCP ${mcpName} for user ${userId}`);
            }

            logger.info(`âœ… Successfully connected MCP ${mcpName} for user ${userId} and workflow task`);
          } else {
            logger.info(`âœ… MCP ${mcpName} already connected for user ${userId}`);
          }
        } catch (error) {
          logger.error(`Failed to ensure MCP connection for ${mcpName} (User: ${userId}):`, error);
          throw new Error(`Failed to connect required MCP service ${mcpName}: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
      }

      logger.info(`âœ… All required MCP services connected for workflow execution (User: ${userId})`);
    } catch (error) {
      logger.error('Failed to ensure workflow MCPs connected:', error);
      throw error;
    }
  }

  /**
   * å¸¦é‡è¯•æœºåˆ¶çš„æ­¥éª¤æ‰§è¡Œ
   */
  private async executeWorkflowStepWithRetry(step: WorkflowStep, state: EnhancedWorkflowState, input: any, actualToolName?: string): Promise<{
    success: boolean;
    result?: any;
    error?: string;
    actualArgs?: any;
  }> {
    let lastError = '';
    const toolName = actualToolName || step.action;
    
    for (let attempt = 1; attempt <= (step.maxRetries || 2) + 1; attempt++) {
      step.attempts = attempt;
      
      try {
        logger.info(`ğŸ”§ Executing ${step.mcp}.${toolName} (attempt ${attempt})`);
        
        const result = await this.executeWorkflowStep(step, state, input, actualToolName);
        
        if (result.success) {
          logger.info(`âœ… Step ${step.step} execution successful on attempt ${attempt}`);
          return result;
        } else {
          lastError = result.error || 'Unknown error';
          logger.warn(`âš ï¸ Step ${step.step} failed on attempt ${attempt}: ${lastError}`);
          
          if (attempt <= (step.maxRetries || 2)) {
            logger.info(`ğŸ”„ Retrying step ${step.step} (${attempt}/${step.maxRetries || 2})`);
            await new Promise(resolve => setTimeout(resolve, 1000 * attempt)); // é€’å¢å»¶è¿Ÿ
          }
        }
      } catch (error) {
        lastError = error instanceof Error ? error.message : String(error);
        logger.error(`âŒ Step ${step.step} execution error on attempt ${attempt}:`, error);
        
        if (attempt <= (step.maxRetries || 2)) {
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        }
      }
    }
    
    return { success: false, error: lastError };
  }

  /**
   * æ‰§è¡Œå•ä¸ªå·¥ä½œæµæ­¥éª¤
   */
  private async executeWorkflowStep(step: WorkflowStep, state: EnhancedWorkflowState, input: any, actualToolName?: string): Promise<{
    success: boolean;
    result?: any;
    error?: string;
    actualArgs?: any;
  }> {
    try {
      const task = await this.taskService.getTaskById(state.taskId);
      if (!task) {
        throw new Error('Task not found');
      }

      // ğŸ”§ æ”¯æŒLLMå·¥å…·å’ŒMCPå·¥å…·
      const isLLMTool = step.mcp === 'llm' || step.mcp.toLowerCase().includes('llm');
      
      if (isLLMTool) {
        // LLMå·¥å…·æ‰§è¡Œ
        const toolName = actualToolName || step.action;
        logger.info(`ğŸ¤– Calling LLM with action: ${toolName}`);
        logger.info(`ğŸ“ Input: ${JSON.stringify(input, null, 2)}`);
        
        const prompt = `Execute ${toolName} with the following input: ${JSON.stringify(input, null, 2)}`;
        const response = await this.llm.invoke([new SystemMessage(prompt)]);
        const result = response.content as string;
        
        logger.info(`âœ… LLM ${toolName} execution successful`);
        return { success: true, result, actualArgs: input };
      } else {
        // MCPå·¥å…·æ‰§è¡Œ - ä½¿ç”¨é¢„æ¨æ–­çš„å®é™…å·¥å…·åç§°
        let toolName = actualToolName;
        if (!toolName) {
          try {
            toolName = await this.inferActualToolName(step.mcp, step.action, input, task.userId);
          } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            logger.error(`âŒ Failed to infer tool name for MCP ${step.mcp} action ${step.action}: ${errorMessage}`);
            throw error;
          }
        }
        
        logger.info(`ğŸ“¡ Calling MCP ${step.mcp} with action: ${step.action} (resolved to: ${toolName})`);
        logger.info(`ğŸ“ Input: ${JSON.stringify(input, null, 2)}`);

        // ğŸ”§ æ–°å¢ï¼šæ™ºèƒ½å‚æ•°è½¬æ¢ï¼Œç¡®ä¿å‚æ•°åä¸å·¥å…· schema åŒ¹é…
        const convertedInput = await this.convertParametersForMCP(step.mcp, toolName, input, task.userId);
        logger.info(`ğŸ“ Converted Input: ${JSON.stringify(convertedInput, null, 2)}`);

        const result = await this.mcpToolAdapter.callTool(
          step.mcp,
          toolName,
          convertedInput,
          task.userId
        );

        logger.info(`âœ… MCP ${step.mcp} execution successful - returning original MCP structure`);
        return { success: true, result, actualArgs: input };
      }

    } catch (error) {
      logger.error(`âŒ Workflow step execution failed:`, error);
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }

  /**
   * ä»ä¸Šä¸‹æ–‡æ¨å¯¼æ­¥éª¤è¾“å…¥å‚æ•°
   */
  private inferStepInputFromContext(step: WorkflowStep, state: EnhancedWorkflowState): any {
    // åŸºäºä¸Šä¸€æ­¥çš„ç»“æœå’Œå½“å‰åŠ¨ä½œæ™ºèƒ½æ¨å¯¼å‚æ•°
    const lastResult = state.dataStore.lastResult;
    const action = step.action.toLowerCase();
    
    // ç®€å•çš„æ¨å¯¼é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
    if (lastResult && typeof lastResult === 'object') {
      if (action.includes('tweet') && lastResult.text) {
        return { content: lastResult.text };
      }
      if (action.includes('search') && lastResult.query) {
        return { query: lastResult.query };
      }
      if (action.includes('get') && lastResult.id) {
        return { id: lastResult.id };
      }
    }
    
    return {};
  }

  /**
   * æ™ºèƒ½æ¨æ–­å®é™…å·¥å…·åç§°ï¼šä½¿ç”¨LLMå°†æè¿°æ€§æ–‡æœ¬è½¬æ¢ä¸ºå®é™…çš„MCPå·¥å…·åç§° (å‚è€ƒAgentå¼•æ“çš„é€šç”¨åšæ³•)
   */
  private async inferActualToolName(mcpName: string, action: string, input: any, userId: string): Promise<string> {
    try {
      // è·å–MCPçš„å¯ç”¨å·¥å…·åˆ—è¡¨
      const tools = await this.mcpManager.getTools(mcpName, userId);
      
      if (!tools || tools.length === 0) {
        logger.warn(`ğŸ” No tools found for MCP ${mcpName}, using original action: ${action}`);
        return action;
      }
      
      const toolNames = tools.map((tool: any) => tool.name);
      logger.info(`ğŸ” Available tools for ${mcpName}: ${toolNames.join(', ')}`);
      
      // 1. é¦–å…ˆæ£€æŸ¥actionæ˜¯å¦å·²ç»æ˜¯æœ‰æ•ˆçš„å·¥å…·åç§°
      if (toolNames.includes(action)) {
        logger.info(`âœ… Action "${action}" is already a valid tool name`);
        return action;
      }
      
      // 2. ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å·¥å…·åç§°æ¨æ–­ (é€šç”¨æ–¹æ³•ï¼Œå‚è€ƒAgentå¼•æ“)
      const toolInferencePrompt = `You are an expert tool name matcher. The requested action "${action}" needs to be mapped to an actual tool name from MCP service "${mcpName}".

CONTEXT:
- Requested action: ${action}
- Input parameters: ${JSON.stringify(input, null, 2)}
- MCP Service: ${mcpName}
- Available tools with descriptions:
${tools.map((tool: any) => {
  return `
Tool: ${tool.name}
Description: ${tool.description || 'No description'}
Input Schema: ${JSON.stringify(tool.inputSchema || {}, null, 2)}
`;
}).join('\n')}

MATCHING PRINCIPLES:
1. **Find functionally equivalent tool**: Select the tool that can accomplish the same objective as the requested action
2. **Consider semantic meaning**: Match based on functionality, not just text similarity
3. **Use exact tool names**: Return the exact tool name from the available list
4. **Prioritize best match**: Choose the most appropriate tool for the requested action

OUTPUT FORMAT:
Return a JSON object with exactly this structure:
{
  "toolName": "exact_tool_name_from_available_list",
  "reasoning": "why this tool was selected for the requested action"
}

Select the best matching tool now:`;

      const response = await this.llm.invoke([new SystemMessage(toolInferencePrompt)]);
      
      try {
        const responseText = response.content.toString().trim();
        logger.info(`ğŸ” === LLM Tool Inference Debug ===`);
        logger.info(`ğŸ” Original Action: ${action}`);
        logger.info(`ğŸ” Raw LLM Response: ${responseText}`);
        
        // ğŸ”§ ä½¿ç”¨Agentå¼•æ“ç›¸åŒçš„JSONæ¸…ç†é€»è¾‘
        let cleanedJson = responseText;
        
        // ç§»é™¤Markdownä»£ç å—æ ‡è®°
        cleanedJson = cleanedJson.replace(/```json\n?/g, '').replace(/```\n?/g, '');
        
        // ğŸ”§ ä½¿ç”¨Agentå¼•æ“çš„JSONæå–é€»è¾‘
        const extractedJson = this.extractCompleteJson(cleanedJson);
        if (extractedJson) {
          cleanedJson = extractedJson;
        }
        
        const inference = JSON.parse(cleanedJson);
        const selectedTool = inference.toolName;
        
        if (selectedTool && toolNames.includes(selectedTool)) {
          logger.info(`âœ… LLM selected tool: ${selectedTool} (${inference.reasoning})`);
          return selectedTool;
        } else {
          logger.warn(`âš ï¸ LLM selected invalid tool: ${selectedTool}, falling back to first available`);
        }
        
      } catch (parseError) {
        logger.error(`âŒ Failed to parse LLM tool inference response: ${response.content}`);
        logger.error(`âŒ Parse error: ${parseError}`);
      }
      
      // 3. å¦‚æœLLMæ¨æ–­å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥å…·ä½œä¸ºé»˜è®¤å€¼
      if (toolNames.length > 0) {
        logger.warn(`ğŸ” Using first available tool as fallback: ${toolNames[0]}`);
        return toolNames[0];
      }
      
      // 4. æœ€åçš„fallback
      logger.warn(`ğŸ” No tools available for MCP ${mcpName}, using original action: ${action}`);
      return action;
      
    } catch (error) {
      logger.error(`âŒ Error inferring tool name for ${mcpName}.${action}:`, error);
      return action; // å¦‚æœæ¨æ–­å¤±è´¥ï¼Œè¿”å›åŸå§‹action
    }
  }

  /**
   * æå–å®Œæ•´JSONå¯¹è±¡ (ä»Agentå¼•æ“å¤åˆ¶)
   */
  private extractCompleteJson(text: string): string | null {
    // æŸ¥æ‰¾ç¬¬ä¸€ä¸ª '{' çš„ä½ç½®
    const startIndex = text.indexOf('{');
    if (startIndex === -1) {
      return null;
    }
    
    // ä» '{' å¼€å§‹ï¼Œæ‰‹åŠ¨åŒ¹é…å¤§æ‹¬å·ä»¥æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
    let braceCount = 0;
    let inString = false;
    let escapeNext = false;
    
    for (let i = startIndex; i < text.length; i++) {
      const char = text[i];
      
      if (escapeNext) {
        escapeNext = false;
        continue;
      }
      
      if (char === '\\' && inString) {
        escapeNext = true;
        continue;
      }
      
      if (char === '"' && !escapeNext) {
        inString = !inString;
        continue;
      }
      
      if (!inString) {
        if (char === '{') {
          braceCount++;
        } else if (char === '}') {
          braceCount--;
          
          // å½“å¤§æ‹¬å·è®¡æ•°ä¸º0æ—¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å®Œæ•´çš„JSONå¯¹è±¡
          if (braceCount === 0) {
            const jsonString = text.substring(startIndex, i + 1);
            logger.info(`ğŸ”§ Extracted complete JSON: ${jsonString}`);
            return jsonString;
          }
        }
      }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼Œè¿”å›null
    logger.warn(`âš ï¸ Could not find complete JSON object`);
    return null;
    }

  /**
   * ğŸ§  æ™ºèƒ½ä»»åŠ¡å¤æ‚åº¦åˆ†æï¼ˆé’ˆå¯¹ä»»åŠ¡å¼•æ“ä¼˜åŒ–ï¼‰
   */
  private async analyzeTaskComplexity(
    query: string, 
    workflowSteps: number
  ): Promise<{
    type: 'simple_query' | 'medium_task' | 'complex_workflow';
    recommendedObservation: 'fast' | 'balanced' | 'thorough';
    shouldCompleteEarly: boolean;
    reasoning: string;
  }> {
    try {
      // ğŸ” åŸºäºæ¨¡å¼çš„å¿«é€Ÿåˆ†æ
      const quickAnalysis = this.quickTaskComplexityAnalysis(query, workflowSteps);
      if (quickAnalysis) {
        return quickAnalysis;
      }

      // ğŸ§  LLMæ·±åº¦åˆ†æï¼ˆç”¨äºè¾¹ç¼˜æƒ…å†µï¼‰
      const analysisPrompt = `Analyze the task complexity for workflow execution and recommend observation strategy.

**User Query**: "${query}"
**Workflow Steps**: ${workflowSteps} steps

**Task Types:**
1. **SIMPLE_QUERY** (Direct data requests):
   - "Show me...", "Get current...", "What is..."
   - Single data point requests
   - Basic information lookup
   - Observation: Fast - complete after first success

2. **MEDIUM_TASK** (Multi-step operations):
   - "Compare X and Y", "Analyze trends"
   - Data processing and basic analysis
   - Sequential operations with dependencies
   - Observation: Balanced - observe key checkpoints

3. **COMPLEX_WORKFLOW** (Comprehensive tasks):
   - Multi-source analysis with transformations
   - Complex decision workflows
   - Extensive data processing chains
   - Observation: Thorough - observe every step

**OUTPUT FORMAT (JSON only):**
{
  "type": "simple_query|medium_task|complex_workflow",
  "recommended_observation": "fast|balanced|thorough",
  "should_complete_early": true/false,
  "reasoning": "Brief explanation of complexity assessment"
}`;

      const response = await this.llm.invoke([new SystemMessage(analysisPrompt)]);
      const content = response.content as string;
      
      // è§£æLLMå“åº”
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        return {
          type: parsed.type || 'medium_task',
          recommendedObservation: parsed.recommended_observation || 'balanced',
          shouldCompleteEarly: parsed.should_complete_early || false,
          reasoning: parsed.reasoning || 'LLM analysis completed'
        };
      }
    } catch (error) {
      logger.warn(`Task complexity analysis failed: ${error}`);
    }

    // é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
    return {
      type: 'medium_task',
      recommendedObservation: 'balanced',
      shouldCompleteEarly: false,
      reasoning: 'Default complexity analysis'
    };
  }

  /**
   * ğŸ” å¿«é€Ÿæ¨¡å¼åŒ¹é…å¤æ‚åº¦åˆ†æï¼ˆé’ˆå¯¹ä»»åŠ¡å¼•æ“ï¼‰
   */
  private quickTaskComplexityAnalysis(
    query: string, 
    workflowSteps: number
  ): {
    type: 'simple_query' | 'medium_task' | 'complex_workflow';
    recommendedObservation: 'fast' | 'balanced' | 'thorough';
    shouldCompleteEarly: boolean;
    reasoning: string;
  } | null {
    const lowerQuery = query.toLowerCase().trim();

    // ğŸŸ¢ ç®€å•æŸ¥è¯¢æ¨¡å¼ (1-2 steps, fast completion)
    const simplePatterns = [
      /^(show me|get|fetch|what is|current|latest)\s/,
      /^(how much|how many|price of|value of)\s/,
      /^(status of|info about|details of)\s/,
      /\b(index|price|value|status|information)\s*(of|for)?\s*\w+$/,
      /^(get current|show current|fetch latest)\s/
    ];

    if (simplePatterns.some(pattern => pattern.test(lowerQuery)) || workflowSteps <= 2) {
      return {
        type: 'simple_query',
        recommendedObservation: 'fast',
        shouldCompleteEarly: true,
        reasoning: 'Direct data query - fast completion after first success'
      };
    }

    // ğŸŸ¡ ä¸­ç­‰ä»»åŠ¡æ¨¡å¼ (3-5 steps, balanced observation)
    const mediumPatterns = [
      /\b(compare|analyze|calculate|process)\b/,
      /\b(then|after|next|followed by)\b/,
      /\b(both|all|multiple|several)\b/,
      /\band\s+\w+\s+(also|too|as well)/,
      /\b(summary|report|overview)\b/
    ];

    if (mediumPatterns.some(pattern => pattern.test(lowerQuery)) || (workflowSteps >= 3 && workflowSteps <= 5)) {
      return {
        type: 'medium_task',
        recommendedObservation: 'balanced',
        shouldCompleteEarly: false,
        reasoning: 'Multi-step task requiring balanced observation'
      };
    }

    // ğŸ”´ å¤æ‚å·¥ä½œæµæ¨¡å¼ (6+ steps, thorough observation)
    const complexPatterns = [
      /\b(workflow|pipeline|process.*step)\b/,
      /\b(first.*then.*finally|step.*step.*step)\b/,
      /\b(comprehensive|detailed|thorough)\s+(analysis|report|study)\b/,
      /\b(multiple.*and.*then)\b/,
      /\b(optimize|automate|integrate)\b/
    ];

    if (complexPatterns.some(pattern => pattern.test(lowerQuery)) || workflowSteps > 5 || lowerQuery.length > 100) {
      return {
        type: 'complex_workflow',
        recommendedObservation: 'thorough',
        shouldCompleteEarly: false,
        reasoning: 'Complex multi-step workflow requiring thorough observation'
      };
    }

    return null; // éœ€è¦LLMæ·±åº¦åˆ†æ
  }

/**
 * ğŸ§  æ–°å¢ï¼šåŠ¨æ€è§„åˆ’é˜¶æ®µï¼ˆå‚è€ƒAgentå¼•æ“ï¼Œä½¿ä»»åŠ¡å¼•æ“ä¹Ÿå…·å¤‡æ™ºèƒ½è§„åˆ’èƒ½åŠ›ï¼‰
 */
private async taskDynamicPlanningPhase(
  state: EnhancedWorkflowState,
  currentContext: string
): Promise<{
  success: boolean;
  adaptedSteps?: Array<{
    step: number;
    mcp: string;
    action: string;
    input?: any;
    reasoning?: string;
  }>;
  error?: string;
}> {
  try {
    // ğŸ”§ è·å–å½“å‰å¯ç”¨çš„MCPå’Œæ‰§è¡Œå†å²
    const availableMCPs = await this.getAvailableMCPsForPlanning(state.taskId);
    const executionHistory = this.buildExecutionHistory(state);
    
    const plannerPrompt = this.buildTaskPlannerPrompt(state, availableMCPs, currentContext, executionHistory);

    // ğŸ”„ ä½¿ç”¨LLMè¿›è¡ŒåŠ¨æ€è§„åˆ’
    const response = await this.llm.invoke([new SystemMessage(plannerPrompt)]);
    const adaptedSteps = this.parseTaskPlan(response.content.toString());

    return { success: true, adaptedSteps };
  } catch (error) {
    logger.error('Task dynamic planning failed:', error);
    return { 
      success: false, 
      error: error instanceof Error ? error.message : String(error) 
    };
  }
}

/**
 * ğŸ§  æ–°å¢ï¼šä»»åŠ¡è§‚å¯Ÿé˜¶æ®µï¼ˆå‚è€ƒAgentå¼•æ“ï¼Œæ™ºèƒ½åˆ†æå½“å‰è¿›åº¦å’Œè°ƒæ•´ç­–ç•¥ï¼‰
 */
private async taskObservationPhase(
  state: EnhancedWorkflowState,
  taskComplexity?: { type: string; recommendedObservation: string; shouldCompleteEarly: boolean; reasoning: string }
): Promise<{
  shouldContinue: boolean;
  shouldAdaptWorkflow: boolean;
  adaptationReason?: string;
  newObjective?: string;
}> {
  try {
    const observerPrompt = this.buildTaskObserverPrompt(state, taskComplexity);
    const response = await this.llm.invoke([new SystemMessage(observerPrompt)]);
    
    return this.parseTaskObservation(response.content.toString());
  } catch (error) {
    logger.error('Task observation failed:', error);
    return { 
      shouldContinue: true, 
      shouldAdaptWorkflow: false 
    };
  }
}

/**
 * ğŸ”§ æ„å»ºä»»åŠ¡è§„åˆ’æç¤ºè¯
 */
private buildTaskPlannerPrompt(
  state: EnhancedWorkflowState,
  availableMCPs: any[],
  currentContext: string,
  executionHistory: string
): string {
  return `You are an intelligent task workflow planner. Based on the current execution context and available tools, dynamically plan the optimal next steps.

**Current Task**: ${state.originalQuery}

**Execution Context**: ${currentContext}

**Available MCP Tools**:
${JSON.stringify(availableMCPs.map(mcp => ({
  name: mcp.name,
  description: mcp.description,
  capabilities: mcp.predefinedTools?.map((tool: any) => tool.name) || []
})), null, 2)}

**Previous Execution History**:
${executionHistory}

**Current Workflow Progress**: ${state.completedSteps}/${state.totalSteps} steps completed

**Instructions**:
1. Analyze what has been accomplished so far
2. Identify what still needs to be done to complete the original task
3. Plan the optimal next steps using available MCP tools
4. Consider efficiency and logical flow
5. Adapt based on previous results

Respond with valid JSON in this exact format:
{
  "analysis": "Brief analysis of current progress and what's needed",
  "adapted_steps": [
    {
      "step": 1,
      "mcp": "mcp_name",
      "action": "Clear description of what this step will accomplish",
      "input": {"actual": "parameters"},
      "reasoning": "Why this step is needed now"
    }
  ],
  "planning_reasoning": "Detailed explanation of the planning logic"
}`;
}

/**
 * ğŸ”§ æ„å»ºä»»åŠ¡è§‚å¯Ÿæç¤ºè¯ï¼ˆæ™ºèƒ½å¤æ‚åº¦æ„ŸçŸ¥ï¼‰
 */
private buildTaskObserverPrompt(
  state: EnhancedWorkflowState,
  taskComplexity?: { type: string; recommendedObservation: string; shouldCompleteEarly: boolean; reasoning: string }
): string {
  return `You are analyzing whether sufficient work has been completed to answer the user's question.

## ğŸ“‹ USER'S ORIGINAL QUESTION
"${state.originalQuery}"

## ğŸ“Š EXECUTION ANALYSIS

### Execution History
${state.executionHistory.map(step => `
**Step ${step.stepNumber}**: ${step.action}
- Status: ${step.success ? 'âœ… Success' : 'âŒ Failed'}
- MCP: ${step.mcpName}
- Data Retrieved: ${step.success && step.result ? 'Yes' : 'No'}
${step.success && step.result ? `- Raw Result Data: ${JSON.stringify(step.result, null, 2)}` : ''}
${step.error ? `- Error: ${step.error}` : ''}
`).join('\n')}

### Critical Analysis Required
**ğŸ” DETAILED COMPARISON NEEDED**:

1. **Parse the user's original request** - What EXACTLY did they ask for?
2. **Analyze the collected data** - What have we actually obtained so far?
3. **Gap Analysis** - What is missing between request and current data?

**ğŸš¨ CRITICAL**: For requests mentioning multiple items/users/targets:
- Count how many were requested vs how many we have data for
- Example: User asks for "A, B, C, D" but we only have data for "A, B" â†’ INCOMPLETE!

## ğŸ§  INTELLIGENT ANALYSIS REQUIRED

**Critical Questions**: 
1. Does the collected data contain the specific information requested by the user?
2. Can you identify and extract the exact answer from the available data?
3. Is the data recent, relevant, and sufficient in scope?

**For "${state.originalQuery}"**:
**INTELLIGENT ANALYSIS**:
Analyze the user's original request: "${state.originalQuery}"

Ask yourself:
1. What EXACTLY did the user ask for?
2. What are the KEY COMPONENTS that must be completed?
3. Are there multiple parts/targets/items mentioned?
4. What is the END GOAL the user wants to achieve?
5. Has that end goal been fully achieved with current data/actions?

**CRITICAL THINKING** (Be extremely thorough):
- Count EXACTLY what the user requested vs what we have
- Don't assume "some data = complete" - verify COMPLETENESS
- For multi-target requests: ALL targets must be processed
- Examine each result summary above: does it contain the requested information?
- Ask: "Would a reasonable person consider this request fully satisfied?"
- If user asked for data on 8 users but we only have 2 â†’ CLEARLY INCOMPLETE
- If user asked for posting/publishing but only collected data â†’ INCOMPLETE
- Use logical reasoning: partial completion â‰  task completion

## ğŸ¯ DECISION LOGIC

**ğŸ§  USE YOUR INTELLIGENCE TO JUDGE**:
- Read the user's original request carefully
- Look at what has been accomplished so far
- Consider whether a reasonable person would say "this request has been fulfilled"
- Don't be overly strict, but also don't accept partial completion as full success
- If the user asked for multiple things, check if ALL of them have been addressed
- If the user asked for an action (like posting), check if that action actually happened

**DECISION GUIDELINES**:
âœ… Mark COMPLETE if: EVERY SINGLE item/user/target in the original request has been processed
âŒ Mark CONTINUE if: ANY item/user/target from the original request is missing

**ğŸš¨ MANDATORY CHECK**: 
- Count total items requested in original query
- Count total items successfully processed  
- If numbers don't match â†’ MUST continue
- Example: 8 users requested, 3 users processed â†’ 5 still missing â†’ CONTINUE!

**OUTPUT FORMAT (JSON only)**:
{
  "shouldContinue": true/false,
  "reasoning": "Focus on whether the specific user question can be answered with available data",
  "newObjective": "If continue, what specific missing information is needed?",
  "shouldAdaptWorkflow": false
}

**ğŸš¨ THINK LIKE A HUMAN**: 
Would a reasonable person consider this request fulfilled based on what has been accomplished? 
Use your intelligence and common sense to make the judgment.`;
}

/**
 * ğŸ”§ è§£æä»»åŠ¡è§„åˆ’ç»“æœ
 */
private parseTaskPlan(content: string): Array<{
  step: number;
  mcp: string;
  action: string;
  input?: any;
  reasoning?: string;
}> {
  try {
    const cleanedContent = content
      .replace(/```json\s*/g, '')
      .replace(/```\s*$/g, '')
      .trim();
    
    const parsed = JSON.parse(cleanedContent);
    return parsed.adapted_steps || [];
  } catch (error) {
    logger.error('Failed to parse task plan:', error);
    return [];
  }
}

/**
 * ğŸ”§ è§£æä»»åŠ¡è§‚å¯Ÿç»“æœ
 */
private parseTaskObservation(content: string): {
  shouldContinue: boolean;
  shouldAdaptWorkflow: boolean;
  adaptationReason?: string;
  newObjective?: string;
} {
  try {
    let jsonText = content.trim();
    jsonText = jsonText.replace(/```json\s*|\s*```/g, '');
    jsonText = jsonText.replace(/```\s*|\s*```/g, '');
    
    const jsonMatch = jsonText.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      const parsed = JSON.parse(jsonMatch[0]);
      
      return {
        shouldContinue: parsed.shouldContinue !== false,
        shouldAdaptWorkflow: parsed.shouldAdaptWorkflow === true,
        adaptationReason: parsed.reasoning,
        newObjective: parsed.newObjective
      };
    }
  } catch (error) {
    logger.warn(`Task observation parsing failed: ${error}`);
  }
  
  // é™çº§æ–¹æ¡ˆ
  return { 
    shouldContinue: true, 
    shouldAdaptWorkflow: false 
  };
}

/**
 * ğŸ”§ è·å–å¯ç”¨äºè§„åˆ’çš„MCPåˆ—è¡¨
 */
private async getAvailableMCPsForPlanning(taskId: string): Promise<any[]> {
  try {
    const task = await this.taskService.getTaskById(taskId);
    if (task?.mcpWorkflow?.mcps) {
      return task.mcpWorkflow.mcps;
    }
    return [];
  } catch (error) {
    logger.error('Failed to get available MCPs for planning:', error);
    return [];
  }
}

  /**
   * ğŸ”§ æ„å»ºæ‰§è¡Œå†å²æ‘˜è¦
   */
  private buildExecutionHistory(state: EnhancedWorkflowState): string {
    if (state.executionHistory.length === 0) {
      return 'No previous execution history.';
    }
    
    return state.executionHistory
      .map(step => `Step ${step.stepNumber}: ${step.action} -> ${step.success ? 'Success' : 'Failed'}`)
      .join('\n');
  }

  /**
   * ğŸ”§ æ„å»ºå½“å‰æ‰§è¡Œä¸Šä¸‹æ–‡
   */
  private buildCurrentContext(state: EnhancedWorkflowState): string {
    const completedSteps = state.executionHistory.filter(step => step.success);
    const failedSteps = state.executionHistory.filter(step => !step.success);
    
    let context = `Current execution context for task: ${state.originalQuery}\n\n`;
    
    // è¿›åº¦æ¦‚è§ˆ
    context += `Progress Overview:\n`;
    context += `- Completed: ${state.completedSteps}/${state.totalSteps} steps\n`;
    context += `- Failed: ${state.failedSteps} steps\n`;
    context += `- Current step index: ${state.currentStepIndex}\n\n`;
    
    // å·²å®Œæˆçš„æ­¥éª¤å’Œç»“æœ
    if (completedSteps.length > 0) {
      context += `Successfully completed steps:\n`;
      completedSteps.forEach(step => {
        const resultSummary = typeof step.result === 'string' 
          ? step.result.substring(0, 100) + '...'
          : JSON.stringify(step.result).substring(0, 100) + '...';
        context += `- Step ${step.stepNumber}: ${step.action} -> ${resultSummary}\n`;
      });
      context += '\n';
    }
    
    // å¤±è´¥çš„æ­¥éª¤
    if (failedSteps.length > 0) {
      context += `Failed steps:\n`;
      failedSteps.forEach(step => {
        context += `- Step ${step.stepNumber}: ${step.action} -> Error: ${step.error}\n`;
      });
      context += '\n';
    }
    
    // å¯ç”¨æ•°æ®
    if (Object.keys(state.dataStore).length > 0) {
      context += `Available data in context:\n`;
      Object.keys(state.dataStore).forEach(key => {
        context += `- ${key}: ${typeof state.dataStore[key]}\n`;
      });
    }
    
    return context;
  }

/**
 * ğŸ”§ æ–°å¢ï¼šæµå¼æ ¼å¼åŒ–ä»»åŠ¡ç»“æœï¼ˆå‚è€ƒAgentå¼•æ“å®ç°ï¼‰
 */
  private async *formatAndStreamTaskResult(
    rawResult: any,
    mcpName: string,
    toolName: string
  ): AsyncGenerator<string, void, unknown> {
    try {
      // ğŸ”§ çº¯ç²¹çš„æ ¼å¼è½¬æ¢ï¼šJSON â†’ Markdownï¼ˆæ™ºèƒ½é•¿åº¦æ§åˆ¶ï¼‰
      const dataString = typeof rawResult === 'string' ? rawResult : JSON.stringify(rawResult, null, 2);
      const isLongData = dataString.length > 3000; // è¶…è¿‡3000å­—ç¬¦è®¤ä¸ºæ˜¯é•¿æ•°æ®
      
      const formatPrompt = `Convert this JSON data to clean, readable Markdown format. Output the formatted Markdown directly without any code blocks or wrappers.

**Data to format:**
${dataString}

**Formatting rules:**
- Convert JSON structure to clear Markdown
- Use tables for object data when helpful
- Use lists for arrays
- Make long numbers readable with commas
- Output the formatted Markdown directly
- DO NOT wrap in code blocks or backticks
- DO NOT add explanations or descriptions

${isLongData ? `
**IMPORTANT - Data Length Control:**
This is a large dataset. Apply smart filtering:
- Show only the most important/commonly used fields
- For blockchain data: show hash, number, gasUsed, gasLimit, miner, timestamp, parentHash
- Skip verbose fields like logsBloom, extraData, mix_hash unless they contain short meaningful values
- For large objects: show top 10-15 most relevant fields
- Always prioritize user-actionable or identifying information
- Keep the output concise and focused
` : `
**Standard formatting:**
- Keep ALL original data values
- Format all available fields
`}
- ONLY return the formatted data`;


      // ä½¿ç”¨æµå¼LLMç”Ÿæˆæ ¼å¼åŒ–ç»“æœ
      const stream = await this.llm.stream([new SystemMessage(formatPrompt)]);

      for await (const chunk of stream) {
        if (chunk.content) {
          yield chunk.content as string;
        }
      }
    } catch (error) {
      logger.error(`Failed to format task result:`, error);
      // é™çº§å¤„ç†ï¼šè¿”å›åŸºæœ¬æ ¼å¼åŒ–
      const fallbackResult = `### ${toolName} æ‰§è¡Œç»“æœ\n\n\`\`\`json\n${JSON.stringify(rawResult, null, 2)}\n\`\`\``;
      yield fallbackResult;
    }
  }

  /**
   * ç”Ÿæˆæ ¼å¼åŒ–ç»“æœï¼ˆéæµå¼ï¼Œç”¨äºå­˜å‚¨ï¼‰
   */
  private async generateFormattedResult(rawResult: any, mcpName: string, action: string): Promise<string> {
    try {
      const dataString = JSON.stringify(rawResult, null, 2);
      // ğŸ”§ ç§»é™¤é•¿æ•°æ®åˆ¤æ–­é™åˆ¶ï¼Œå…è®¸å¤„ç†ä»»æ„é•¿åº¦çš„æ•°æ®
      const isLongData = false; // dataString.length > 3000; // ç§»é™¤3000å­—ç¬¦é™åˆ¶
      
      const prompt = `Convert this JSON data to clean, readable Markdown format. Output the formatted Markdown directly without any code blocks or wrappers.

**Data to format:**
${dataString}

**Formatting rules:**
- Convert JSON structure to clear Markdown
- Use tables for object data when helpful
- Use lists for arrays
- Make long numbers readable with commas
- Output the formatted Markdown directly
- DO NOT wrap in code blocks or backticks
- DO NOT add explanations or descriptions

${isLongData ? `
**IMPORTANT - Data Length Control:**
This is a large dataset. Apply smart filtering:
- Show only the most important/commonly used fields
- For blockchain data: show hash, number, gasUsed, gasLimit, miner, timestamp, parentHash
- Skip verbose fields like logsBloom, extraData, mix_hash unless they contain short meaningful values
- For large objects: show top 10-15 most relevant fields
- Always prioritize user-actionable or identifying information
- Keep the output concise and focused
` : `
**Standard formatting:**
- Keep ALL original data values
- Format all available fields
`}
- ONLY return the formatted data`;

      const response = await this.llm.invoke([new SystemMessage(prompt)]);
      return response.content as string;
    } catch (error) {
      logger.error('Failed to format result:', error);
      return JSON.stringify(rawResult, null, 2);
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºMCPè¿æ¥é”™è¯¯
   */
  private isMCPConnectionError(error: string): boolean {
    const lowerError = error.toLowerCase();
    return lowerError.includes('mcp') || 
           lowerError.includes('connection') || 
           lowerError.includes('auth') ||
           lowerError.includes('not connected');
  }

  /**
   * ç”Ÿæˆå·¥ä½œæµæœ€ç»ˆç»“æœ
   */
  private generateWorkflowFinalResult(state: EnhancedWorkflowState): string {
    const successRate = Math.round((state.completedSteps / state.totalSteps) * 100);
    
    let summary = `Workflow execution completed with ${successRate}% success rate.\n\n`;
    summary += `**Execution Summary:**\n`;
    summary += `- Total Steps: ${state.totalSteps}\n`;
    summary += `- Completed: ${state.completedSteps}\n`;
    summary += `- Failed: ${state.failedSteps}\n\n`;
    
    if (state.completedSteps > 0) {
      summary += `**Successful Steps:**\n`;
      state.executionHistory
        .filter(entry => entry.success)
        .forEach(entry => {
          summary += `- Step ${entry.stepNumber}: ${entry.mcpName}.${entry.action} âœ…\n`;
        });
    }
    
    if (state.failedSteps > 0) {
      summary += `\n**Failed Steps:**\n`;
      state.executionHistory
        .filter(entry => !entry.success)
        .forEach(entry => {
          summary += `- Step ${entry.stepNumber}: ${entry.mcpName}.${entry.action} âŒ (${entry.error})\n`;
        });
    }
    
    return summary;
  }



  /**
   * ä¿å­˜æ­¥éª¤åŸå§‹ç»“æœæ¶ˆæ¯
   */
  private async saveStepRawResult(taskId: string, stepNumber: number, step: WorkflowStep, rawResult: any, actualArgs: any, toolType: string, mcpName: string | null, expectedOutput: string, reasoning: string, actualToolName?: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„contentæ ¼å¼å’Œmetadataç»“æ„
        const toolName = actualToolName || step.action;
        const rawContent = `WorkflowEngine Step ${stepNumber} Raw Result: ${toolName}

${JSON.stringify(rawResult, null, 2)}`;

        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: rawContent,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.EXECUTION,
            stepNumber: stepNumber,
            stepName: toolName,
            taskPhase: 'execution',
            contentType: 'raw_result',
            agentName: 'WorkflowEngine',
            isComplete: true,
            toolDetails: {
              toolType: toolType,
              toolName: toolName,
              mcpName: mcpName,
              args: actualArgs || step.input || {},
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            },
            executionDetails: {
              rawResult: rawResult,
              success: true,
              processingInfo: {
                originalDataSize: JSON.stringify(rawResult).length,
                processingTime: new Date().toISOString()
              }
            }
          }
        });

        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error(`Failed to save workflow step raw result:`, error);
    }
  }

  /**
   * ä¿å­˜æ­¥éª¤æ ¼å¼åŒ–ç»“æœæ¶ˆæ¯
   */
  private async saveStepFormattedResult(taskId: string, stepNumber: number, step: WorkflowStep, formattedResult: string, actualArgs: any, toolType: string, mcpName: string | null, expectedOutput: string, reasoning: string, actualToolName?: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„contentæ ¼å¼å’Œmetadataç»“æ„
        const toolName = actualToolName || step.action;
        const resultType = toolType === 'llm' ? 'LLM Result' : 'Formatted Result';
        const formattedContent = `WorkflowEngine Step ${stepNumber} ${resultType}: ${toolName}

${formattedResult}`;

        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: formattedContent,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.EXECUTION,
            stepNumber: stepNumber,
            stepName: toolName,
            taskPhase: 'execution',
            contentType: 'formatted_result',
            agentName: 'WorkflowEngine',
            isComplete: true,
            toolDetails: {
              toolType: toolType,
              toolName: toolName,
              mcpName: mcpName,
              args: actualArgs || step.input || {},
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            },
            executionDetails: {
              formattedResult: formattedResult,
              success: true,
              processingInfo: {
                formattedDataSize: formattedResult.length,
                processingTime: new Date().toISOString()
              }
            }
          }
        });

        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error(`Failed to save workflow step formatted result:`, error);
    }
  }

  /**
   * ä¿å­˜ä»»åŠ¡æœ€ç»ˆç»“æœ
   */
  private async saveWorkflowFinalResult(taskId: string, state: EnhancedWorkflowState, finalResult: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: `Workflow Final Result:\n\n${finalResult}`,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.SUMMARY,
            stepName: 'Workflow Completion',
            taskPhase: 'completion',
            isComplete: true,
            executionSummary: {
              totalSteps: state.totalSteps,
              completedSteps: state.completedSteps,
              failedSteps: state.failedSteps,
              successRate: Math.round((state.completedSteps / state.totalSteps) * 100)
            }
          }
        });
        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error('Failed to save workflow final result:', error);
    }
  }

  /**
   * ğŸ¯ æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿæ•°æ®ï¼ˆå‚è€ƒAgentå¼•æ“çš„ç›´æ¥åˆ¤æ–­æ–¹æ³•ï¼‰
   */
  private async hasTaskCollectedSufficientData(state: EnhancedWorkflowState): Promise<boolean> {
    // åŸºäºæ•°æ®å­˜å‚¨å’Œæ‰§è¡Œå†å²çš„å¿«é€Ÿåˆ¤æ–­
    const hasSuccessfulSteps = state.completedSteps > 0;
    const hasUsefulData = Object.keys(state.dataStore).length > 1; // é™¤äº† lastResult è¿˜æœ‰å…¶ä»–æ•°æ®
    
    return hasSuccessfulSteps && hasUsefulData;
  }

  /**
   * ğŸ¯ å¿«é€Ÿä»»åŠ¡å®Œæˆæ£€æŸ¥ï¼ˆå‚è€ƒAgentå¼•æ“çš„ç®€åŒ–åˆ¤æ–­é€»è¾‘ï¼‰
   */
  // ğŸ”§ ç§»é™¤ç¡¬ç¼–ç çš„å¿«é€Ÿå®Œæˆæ£€æŸ¥ï¼Œç°åœ¨ä½¿ç”¨æ™ºèƒ½è§‚å¯Ÿé˜¶æ®µ

  /**
   * ğŸ¯ ç®€åŒ–çš„å·¥ä½œæµé€‚åº”åˆ¤æ–­ï¼ˆå‡å°‘å¤æ‚åº¦ï¼‰
   */
  private async shouldAdaptWorkflow(state: EnhancedWorkflowState, currentStep: WorkflowStep): Promise<boolean> {
    // ç®€åŒ–çš„é€‚åº”åˆ¤æ–­ï¼šåªåœ¨è¿ç»­å¤±è´¥æ—¶é€‚åº”
    const recentFailures = state.executionHistory
      .slice(-2) // æœ€è¿‘2æ­¥
      .filter(step => !step.success);
    
    return recentFailures.length >= 2; // è¿ç»­2æ­¥å¤±è´¥æ‰é€‚åº”
  }

  /**
   * ğŸ”§ æ–°å¢ï¼šä¸º MCP è½¬æ¢å‚æ•°ï¼Œç¡®ä¿å‚æ•°åä¸å·¥å…· schema åŒ¹é…
   */
  private async convertParametersForMCP(mcpName: string, toolName: string, input: any, userId: string): Promise<any> {
    try {
      logger.info(`ğŸ”„ Converting parameters for MCP tool: ${mcpName}.${toolName}`);

      // è·å– MCP å·¥å…·çš„ schema
      const mcpTools = await this.mcpManager.getTools(mcpName, userId);
      const targetTool = mcpTools.find(tool => tool.name === toolName);
      
      if (!targetTool || !targetTool.inputSchema) {
        logger.info(`ğŸ” No schema found for ${mcpName}.${toolName}, returning original input`);
        return input;
      }

      // æ‰§è¡Œå‚æ•°åè½¬æ¢
      const convertedParams = this.preprocessParameterNames(input, targetTool.inputSchema);
      
      if (JSON.stringify(convertedParams) !== JSON.stringify(input)) {
        logger.info(`ğŸ”§ Parameters converted for ${mcpName}.${toolName}: ${JSON.stringify(input)} â†’ ${JSON.stringify(convertedParams)}`);
      }

      return convertedParams;

    } catch (error) {
      logger.error(`âŒ Parameter conversion failed for ${mcpName}.${toolName}:`, error);
      return input; // å›é€€åˆ°åŸå§‹è¾“å…¥
    }
  }

  /**
   * ğŸ”§ æ–°å¢ï¼šé¢„å¤„ç†å‚æ•°åï¼ˆcamelCase åˆ° snake_caseï¼‰
   */
  private preprocessParameterNames(originalArgs: any, inputSchema: any): any {
    if (!originalArgs || typeof originalArgs !== 'object') {
      return originalArgs;
    }

    const schemaProperties = inputSchema.properties || {};
    const expectedParamNames = Object.keys(schemaProperties);
    
    logger.info(`ğŸ”§ Preprocessing parameters, expected: [${expectedParamNames.join(', ')}]`);

    const processedArgs: any = {};
    
    for (const [key, value] of Object.entries(originalArgs)) {
      let mappedKey = key;
      
      // æ£€æŸ¥æ˜¯å¦éœ€è¦ camelCase -> snake_case è½¬æ¢
      if (!expectedParamNames.includes(key)) {
        const snakeCaseKey = this.camelToSnakeCase(key);
        if (expectedParamNames.includes(snakeCaseKey)) {
          mappedKey = snakeCaseKey;
          logger.info(`ğŸ”§ Parameter name mapped: ${key} -> ${mappedKey}`);
        }
      }
      
      processedArgs[mappedKey] = value;
    }

    return processedArgs;
  }

  /**
   * ğŸ”§ æ–°å¢ï¼šcamelCase è½¬ snake_case
   */
  private camelToSnakeCase(str: string): string {
    return str.replace(/([a-z])([A-Z])/g, '$1_$2').toLowerCase();
  }


}

/**
 * å¢å¼ºçš„æ™ºèƒ½TaskæœåŠ¡ - åŸºäºå·¥ä½œæµæ‰§è¡Œ
 */
export class EnhancedIntelligentTaskService {
  private engine: EnhancedIntelligentTaskEngine;
  private taskService: any;

  constructor() {
    this.engine = new EnhancedIntelligentTaskEngine();
    this.taskService = getTaskService();
  }

  /**
   * æ‰§è¡Œå¢å¼ºçš„æ™ºèƒ½Task - åŸºäºå·²æ„å»ºçš„å·¥ä½œæµ
   */
  async executeTaskEnhanced(
    taskId: string,
    stream: (data: any) => void,
    skipAnalysisCheck: boolean = false
  ): Promise<boolean> {
    try {
      logger.info(`âš¡ Starting enhanced workflow-based task execution [Task: ${taskId}]`);

      // è·å–ä»»åŠ¡ä¿¡æ¯
      const task = await this.taskService.getTaskById(taskId);
      if (!task) {
        // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
        stream({ 
          event: 'error', 
          data: { 
            message: 'Task not found'
          }
        });
        return false;
      }

      // æ£€æŸ¥æ˜¯å¦å·²æœ‰å·¥ä½œæµ
      const mcpWorkflow = typeof task.mcpWorkflow === 'string' 
        ? JSON.parse(task.mcpWorkflow) 
        : task.mcpWorkflow;

      if (!skipAnalysisCheck && (!mcpWorkflow || !mcpWorkflow.workflow || mcpWorkflow.workflow.length === 0)) {
        // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
        stream({ 
          event: 'error', 
          data: { 
            message: 'No workflow found. Please analyze the task first.',
            details: 'Call /api/task/:id/analyze to generate a workflow before execution.'
          }
        });
        return false;
      }

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await taskExecutorDao.updateTaskStatus(taskId, 'in_progress');
      // ğŸ”§ å‘é€çŠ¶æ€æ›´æ–°äº‹ä»¶
      stream({ 
        event: 'status_update', 
        data: { 
          status: 'in_progress'
        }
      });

      // ä½¿ç”¨å¢å¼ºå¼•æ“æ‰§è¡Œå·¥ä½œæµ
      const executionGenerator = this.engine.executeWorkflowEnhanced(taskId, mcpWorkflow);

      let finalSuccess = false;

      for await (const result of executionGenerator) {
        // ğŸ”§ ç›´æ¥æµå¼ä¼ è¾“åŸå§‹äº‹ä»¶ï¼Œä¸åŒ…è£…
        stream(result);
        
        // è®°å½•æœ€ç»ˆæ‰§è¡Œç»“æœ
        if (result.event === 'final_result') {
          finalSuccess = result.data.success;
        }
      }

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await taskExecutorDao.updateTaskStatus(
        taskId, 
        finalSuccess ? 'completed' : 'failed'
      );

      // ğŸ”§ å‘é€æ‰§è¡Œå®Œæˆäº‹ä»¶
      stream({
        event: 'task_execution_complete',
        data: {
          success: finalSuccess,
          message: finalSuccess ? 
            'Task execution completed successfully' : 
            'Task execution failed'
        }
      });

      logger.info(`âœ… Enhanced workflow execution completed [Task: ${taskId}, Success: ${finalSuccess}]`);
      return finalSuccess;

    } catch (error) {
      logger.error(`âŒ Enhanced workflow execution failed:`, error);
      
      // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
      stream({
        event: 'error',
        data: {
          message: 'Enhanced workflow execution failed',
          details: error instanceof Error ? error.message : String(error)
        }
      });

      await taskExecutorDao.updateTaskStatus(taskId, 'failed');
      return false;
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const enhancedIntelligentTaskService = new EnhancedIntelligentTaskService(); 
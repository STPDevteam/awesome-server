import { ChatOpenAI } from '@langchain/openai';
import { HumanMessage, SystemMessage } from '@langchain/core/messages';
import { logger } from '../utils/logger.js';
import { MCPManager } from './mcpManager.js';
import { MCPToolAdapter } from './mcpToolAdapter.js';
import { MCPAuthService } from './mcpAuthService.js';
import { getTaskService } from './taskService.js';
import { taskExecutorDao } from '../dao/taskExecutorDao.js';
import { messageDao } from '../dao/messageDao.js';
import { conversationDao } from '../dao/conversationDao.js';
import { MessageType, MessageIntent, MessageStepType } from '../models/conversation.js';

/**
 * å·¥ä½œæµæ­¥éª¤ - åŸºäºTaskAnalysisServiceæ„å»ºçš„ç»“æ„
 */
export interface WorkflowStep {
  step: number;
  mcp: string;
  action: string;
  input?: any;
  // å¢å¼ºå­—æ®µ
  status?: 'pending' | 'executing' | 'completed' | 'failed';
  result?: any;
  error?: string;
  attempts?: number;
  maxRetries?: number;
}

/**
 * å¢å¼ºçš„å·¥ä½œæµçŠ¶æ€
 */
export interface EnhancedWorkflowState {
  taskId: string;
  originalQuery: string;
  workflow: WorkflowStep[];
  currentStepIndex: number;
  executionHistory: Array<{
    stepNumber: number;
    mcpName: string;
    action: string;
    success: boolean;
    result?: any;
    error?: string;
    timestamp: Date;
  }>;
  dataStore: Record<string, any>;
  isComplete: boolean;
  totalSteps: number;
  completedSteps: number;
  failedSteps: number;
}

/**
 * å¢å¼ºçš„æ™ºèƒ½Taskæ‰§è¡Œå¼•æ“
 * ä¸“æ³¨äºæ‰§è¡Œå·²æ„å»ºçš„MCPå·¥ä½œæµï¼Œç»“åˆAgentå¼•æ“çš„æ™ºèƒ½åŒ–ä¼˜åŠ¿
 */
export class EnhancedIntelligentTaskEngine {
  private llm: ChatOpenAI;
  private mcpManager: MCPManager;
  private mcpToolAdapter: MCPToolAdapter;
  private mcpAuthService: MCPAuthService;
  private taskService: any;

  constructor() {
    this.llm = new ChatOpenAI({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'gpt-4o',
      temperature: 0.1,
    });

    this.mcpManager = new MCPManager();
    this.mcpToolAdapter = new MCPToolAdapter(this.mcpManager);
    this.mcpAuthService = new MCPAuthService();
    this.taskService = getTaskService();
  }

  /**
   * å¢å¼ºçš„Taskæµå¼æ‰§è¡Œ - åŸºäºå·²æ„å»ºçš„å·¥ä½œæµ
   */
  async *executeWorkflowEnhanced(
    taskId: string,
    mcpWorkflow: any
  ): AsyncGenerator<{ event: string; data: any }, boolean, unknown> {
    
    // ğŸ”§ CRITICAL DEBUG: ç¡®è®¤è¿›å…¥Enhancedå¼•æ“
    logger.info(`ğŸš¨ ENHANCED ENGINE STARTED - Task: ${taskId}`);
    logger.info(`ğŸš€ Starting enhanced workflow execution [Task: ${taskId}]`);

    // ğŸ”§ éªŒè¯å·¥ä½œæµç»“æ„
    if (!mcpWorkflow || !mcpWorkflow.workflow || mcpWorkflow.workflow.length === 0) {
      yield {
        event: 'error',
        data: { 
          message: 'No valid workflow found. Please run task analysis first.',
          details: 'The task must be analyzed to generate a workflow before execution.'
        }
      };
      return false;
    }

    // ğŸ§  æ™ºèƒ½ä»»åŠ¡å¤æ‚åº¦åˆ†æ
    const task = await this.taskService.getTaskById(taskId);
    const taskQuery = task?.content || '';
    const taskComplexity = await this.analyzeTaskComplexity(taskQuery, mcpWorkflow.workflow.length);
    
    logger.info(`ğŸ¯ Task complexity analysis: ${taskComplexity.type} (${taskComplexity.recommendedObservation})`);

    // ğŸ”§ æ ¹æ®å¤æ‚åº¦è°ƒæ•´æ‰§è¡Œç­–ç•¥
    const shouldObserveEveryStep = taskComplexity.type !== 'simple_query';

    // ğŸ”§ å‘é€æ‰§è¡Œå¼€å§‹äº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œäº‹ä»¶åç§°
    yield {
      event: 'execution_start',
      data: {
        taskId,
        agentName: 'WorkflowEngine',
        taskComplexity: taskComplexity.type,
        observationStrategy: taskComplexity.recommendedObservation,
        timestamp: new Date().toISOString(),
        message: `Starting execution...`,
        mode: 'enhanced',
        workflowInfo: {
          totalSteps: mcpWorkflow.workflow.length,
          mcps: mcpWorkflow.mcps?.map((mcp: any) => mcp.name) || []
        }
      }
    };

    // ğŸ”§ åˆå§‹åŒ–å¢å¼ºçš„å·¥ä½œæµçŠ¶æ€
    const state: EnhancedWorkflowState = {
      taskId,
      originalQuery: '', // ä»taskè·å–
      workflow: mcpWorkflow.workflow.map((step: any, index: number) => ({
        ...step,
        status: 'pending',
        attempts: 0,
        maxRetries: 2
      })),
      currentStepIndex: 0,
      executionHistory: [],
      dataStore: {},
      isComplete: false,
      totalSteps: mcpWorkflow.workflow.length,
      completedSteps: 0,
      failedSteps: 0
    };

    try {
      // ğŸ”§ è·å–ä»»åŠ¡ä¿¡æ¯
      const task = await this.taskService.getTaskById(taskId);
      if (task) {
        state.originalQuery = task.content;
      }

      // ğŸ”§ å‡†å¤‡æ‰§è¡Œç¯å¢ƒ
      await this.prepareWorkflowExecution(taskId, state, mcpWorkflow);

      // ğŸ”§ ç§»é™¤workflow_execution_startäº‹ä»¶ï¼Œç›´æ¥å¼€å§‹æ­¥éª¤æ‰§è¡Œ

      for (let i = 0; i < state.workflow.length; i++) {
        const currentStep = state.workflow[i];
        state.currentStepIndex = i;

        logger.info(`ğŸ§  Executing workflow step ${currentStep.step}: ${currentStep.mcp}.${currentStep.action}`);

        // ğŸ”§ é¢„å¤„ç†å‚æ•°ï¼šæ™ºèƒ½å‚æ•°å¤„ç†ï¼Œå¦‚æœinputä¸ºç©ºï¼Œå°è¯•ä»ä¸Šä¸‹æ–‡æ¨å¯¼
        let processedInput = currentStep.input || {};
        if (!currentStep.input && state.dataStore.lastResult) {
          processedInput = this.inferStepInputFromContext(currentStep, state);
        }

        // ğŸ”§ ç¡®å®šå·¥å…·ç±»å‹å’Œæ™ºèƒ½æè¿° - ä¸Agentå¼•æ“ä¸€è‡´
        const isLLMTool = currentStep.mcp === 'llm' || currentStep.mcp.toLowerCase().includes('llm');
        const toolType = isLLMTool ? 'llm' : 'mcp';
        const mcpName = isLLMTool ? null : currentStep.mcp;
        
        // ğŸ”§ é¢„å…ˆæ¨æ–­å®é™…å·¥å…·åç§°
        let actualToolName = currentStep.action;
        if (!isLLMTool) {
          const task = await this.taskService.getTaskById(state.taskId);
          if (task) {
            logger.info(`ğŸ” Inferring tool name for step ${currentStep.step}: ${currentStep.mcp}.${currentStep.action}`);
            actualToolName = await this.inferActualToolName(currentStep.mcp, currentStep.action, processedInput, task.userId);
            logger.info(`âœ… Tool name inference completed: ${actualToolName}`);
          }
        }

        // ğŸ”§ ç”Ÿæˆç®€å•çš„expectedOutputå’Œreasoningï¼ˆä½¿ç”¨å®é™…å·¥å…·åç§°ï¼‰
        const expectedOutput = isLLMTool 
          ? `AI analysis and processing for ${actualToolName}`
          : `Execute ${actualToolName} on ${currentStep.mcp}`;
        const reasoning = `Workflow step ${currentStep.step}`;

        // ğŸ”§ å‘é€æ­¥éª¤å¼€å§‹äº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œäº‹ä»¶åç§°
        const stepId = `workflow_step_${currentStep.step}_${Date.now()}`;
        yield {
          event: 'step_executing',
          data: {
            step: currentStep.step,
            mcpName: mcpName || currentStep.mcp,
            actionName: actualToolName,
            input: JSON.stringify(processedInput),
            agentName: 'WorkflowEngine',
            message: `WorkflowEngine is executing step ${currentStep.step}: ${actualToolName}`,
            // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„toolDetailsç»“æ„
            toolDetails: {
              toolType: toolType,
              toolName: actualToolName,
              mcpName: mcpName,
              args: processedInput,
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            }
          }
        };

        // ğŸ”§ æ‰§è¡Œå½“å‰æ­¥éª¤ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰- ä¼ é€’é¢„å¤„ç†çš„å‚æ•°å’Œå®é™…å·¥å…·åç§°
        logger.info(`ğŸ”„ Starting execution for step ${currentStep.step} with tool: ${actualToolName}`);
        const executionResult = await this.executeWorkflowStepWithRetry(currentStep, state, processedInput, actualToolName);
        logger.info(`ğŸ“‹ Execution result:`, {
          success: executionResult.success,
          hasResult: !!executionResult.result,
          resultSize: executionResult.result ? JSON.stringify(executionResult.result).length : 0,
          error: executionResult.error || 'none'
        });

        // ğŸ”§ CRITICAL: æ£€æŸ¥æ˜¯å¦åˆ°è¾¾äº†åç»­å¤„ç†é˜¶æ®µ
        logger.info(`ğŸ¯ REACHED POST-EXECUTION PROCESSING - Step ${currentStep.step}`);

        // ğŸ”§ è®°å½•æ‰§è¡Œå†å²
        const historyEntry = {
          stepNumber: currentStep.step,
          mcpName: currentStep.mcp,
          action: currentStep.action,
          success: executionResult.success,
          result: executionResult.result,
          error: executionResult.error,
          timestamp: new Date()
        };
        state.executionHistory.push(historyEntry);

        // ğŸ”§ é‡è¦è°ƒè¯•ï¼šæ£€æŸ¥executionResultçš„ç»“æ„
        logger.info(`ğŸ” CRITICAL DEBUG - executionResult:`, {
          success: executionResult.success,
          hasResult: !!executionResult.result,
          resultType: typeof executionResult.result,
          resultKeys: executionResult.result ? Object.keys(executionResult.result) : 'no result'
        });

        // ğŸ”§ å‘é€step_raw_resultäº‹ä»¶ï¼ˆæ–°å¢äº‹ä»¶ï¼‰
        if (executionResult.success && executionResult.result) {
          logger.info(`ğŸ¯ CRITICAL DEBUG - Conditions met, yielding step_raw_result`);
          
          yield {
            event: 'step_raw_result',
            data: {
              step: currentStep.step,
              success: true,
              result: executionResult.result,  // åŸå§‹MCPæ•°æ®ç»“æ„
              agentName: 'WorkflowEngine',
              executionDetails: {
                toolType: toolType,
                toolName: actualToolName,
                mcpName: mcpName,
                // ğŸ”§ ç§»é™¤rawResulté‡å¤ - æ•°æ®å·²åœ¨ä¸Šé¢çš„resultå­—æ®µä¸­
                args: executionResult.actualArgs || currentStep.input || {},
                expectedOutput: expectedOutput,
                timestamp: new Date().toISOString()
              }
            }
          };

          // ğŸ”§ å¼‚æ­¥ä¿å­˜åŸå§‹ç»“æœï¼Œé¿å…é˜»å¡æµå¼å“åº”
          this.saveStepRawResult(taskId, currentStep.step, currentStep, executionResult.result, executionResult.actualArgs, toolType, mcpName, expectedOutput, reasoning, actualToolName).catch(error => {
            logger.error(`Failed to save step raw result:`, error);
          });
        }

        // ğŸ”§ æµå¼æ ¼å¼åŒ–ç»“æœå¤„ç†ï¼ˆå‚è€ƒAgentå¼•æ“ï¼‰
        let formattedResult = '';
        if (executionResult.success && executionResult.result) {
          // ğŸ”§ æµå¼æ ¼å¼åŒ–ï¼šå…ˆå‘é€æµå¼æ ¼å¼åŒ–å—ï¼ˆä»…å¯¹MCPå·¥å…·ï¼‰
          if (toolType === 'mcp') {
            const formatGenerator = this.formatAndStreamTaskResult(
              executionResult.result,
              currentStep.mcp,
              actualToolName
            );

            // ğŸ”§ ä½¿ç”¨å‰ç«¯å¯¹åº”çš„äº‹ä»¶åç§°
            if (currentStep.step === state.totalSteps) {
              // æœ€åä¸€æ­¥ï¼šå‘é€step_startäº‹ä»¶ç„¶åä½¿ç”¨summary_chunkäº‹ä»¶
              yield {
                event: 'step_start',
                data: {
                  message: `Running ${mcpName || ''} - ${actualToolName || ''}`,
                  agentName: 'WorkflowEngine'
                }
              };
              
              for await (const chunk of formatGenerator) {
                yield {
                  event: 'summary_chunk',
                  data: {
                    content: chunk,
                    agentName: 'WorkflowEngine'
                  }
                };
              }
            } else {
              // ä¸­é—´æ­¥éª¤ï¼šæš‚æ—¶è·³è¿‡æµå¼è¾“å‡ºï¼Œåªä¿ç•™æœ€ç»ˆæ ¼å¼åŒ–ç»“æœ
            }
          }

          // ğŸ”§ ç”Ÿæˆå®Œæ•´çš„æ ¼å¼åŒ–ç»“æœç”¨äºå­˜å‚¨å’Œæœ€ç»ˆäº‹ä»¶
          formattedResult = await this.generateFormattedResult(
            executionResult.result,
            currentStep.mcp,
            actualToolName
          );

          // ğŸ”§ ç§»é™¤step_formatted_resultäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦

          // ğŸ”§ å¼‚æ­¥ä¿å­˜æ ¼å¼åŒ–ç»“æœï¼Œé¿å…é˜»å¡æµå¼å“åº”
          this.saveStepFormattedResult(taskId, currentStep.step, currentStep, formattedResult, executionResult.actualArgs, toolType, mcpName, expectedOutput, reasoning, actualToolName).catch(error => {
            logger.error(`Failed to save step formatted result:`, error);
          });

          // ğŸ”§ æ›´æ–°æ•°æ®å­˜å‚¨
          state.dataStore[`step_${currentStep.step}_result`] = executionResult.result;
          state.dataStore.lastResult = executionResult.result;
        }

        // ğŸ”§ æ›´æ–°æ­¥éª¤çŠ¶æ€
        if (executionResult.success) {
          currentStep.status = 'completed';
          state.completedSteps++;
          
          // ğŸ”§ å‘é€step_completeäº‹ä»¶ - å¯¹é½ä¼ ç»Ÿä»»åŠ¡æ‰§è¡Œæ ¼å¼
          yield {
            event: 'step_complete',
            data: {
              step: currentStep.step,
              success: true,
              result: formattedResult || executionResult.result, // æ ¼å¼åŒ–ç»“æœä¾›å‰ç«¯æ˜¾ç¤º
              rawResult: executionResult.result, // ä¿ç•™åŸå§‹MCPç»“æœä¾›è°ƒè¯•
              // ğŸ”§ ä¿ç•™æ™ºèƒ½å¼•æ“çš„å¢å¼ºå­—æ®µ
              agentName: 'WorkflowEngine',
              message: `WorkflowEngine completed step ${currentStep.step} successfully`,
              progress: {
                completed: state.completedSteps,
                total: state.totalSteps,
                percentage: Math.round((state.completedSteps / state.totalSteps) * 100)
              }
            }
          };
        } else {
          currentStep.status = 'failed';
          state.failedSteps++;

          // ğŸ”§ å‘é€step_erroräº‹ä»¶ - ç®€åŒ–æ ¼å¼
          yield {
            event: 'step_error',
            data: {
              step: currentStep.step,
              error: executionResult.error,
              agentName: 'WorkflowEngine'
            }
          };
        }

        // ğŸ¯ ç›´æ¥ä»»åŠ¡å®Œæˆæ„ŸçŸ¥ - å‚è€ƒAgentå¼•æ“çš„ä¼˜åŒ–æ–¹æ¡ˆ
        let shouldContinue = true;

        // ğŸ”§ æ™ºèƒ½å®Œæˆæ£€æµ‹ï¼šåŸºäºä»»åŠ¡å¤æ‚åº¦å’Œæ‰§è¡Œç»“æœè¿›è¡Œç›´æ¥åˆ¤æ–­
        if (executionResult.success) {
          if (taskComplexity.type === 'simple_query') {
            // ç®€å•æŸ¥è¯¢ï¼šç¬¬ä¸€æ­¥æˆåŠŸå³å®Œæˆ
            if (i === 0) {
              logger.info(`ğŸ¯ Simple query completed successfully after first step, stopping execution`);
              shouldContinue = false;
            }
          } else if (taskComplexity.type === 'medium_task') {
            // ä¸­ç­‰ä»»åŠ¡ï¼šæ£€æŸ¥æ˜¯å¦å·²è·å¾—è¶³å¤Ÿæ•°æ®
            const hasUsefulData = await this.hasTaskCollectedSufficientData(state);
            if (hasUsefulData) {
              logger.info(`ğŸ¯ Medium task collected sufficient data, evaluating completion`);
              shouldContinue = await this.quickTaskCompletionCheck(state, taskComplexity);
            }
          } else {
            // å¤æ‚å·¥ä½œæµï¼šæ¯éš”2æ­¥æ£€æŸ¥ä¸€æ¬¡å®ŒæˆçŠ¶æ€
            if (i % 2 === 0) {
              logger.info(`ğŸ” Complex workflow checkpoint at step ${i + 1}`);
              shouldContinue = await this.quickTaskCompletionCheck(state, taskComplexity);
            }
          }
        }

        // ğŸ”§ ç§»é™¤task_observationäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦
        
        // ğŸ”„ ç®€åŒ–åŠ¨æ€è§„åˆ’é€»è¾‘ï¼ˆä¿ç•™å·¥ä½œæµé€‚åº”èƒ½åŠ›ä½†å‡å°‘å¤æ‚åº¦ï¼‰
        let shouldAdaptWorkflow = false;
        
        // åªåœ¨å¤±è´¥æ—¶è€ƒè™‘å·¥ä½œæµé€‚åº”
        if (!executionResult.success && i < state.workflow.length - 2) {
          shouldAdaptWorkflow = await this.shouldAdaptWorkflow(state, currentStep);
        }
        
        if (shouldAdaptWorkflow) {
          logger.info(`ğŸ§  Initiating dynamic workflow adaptation...`);
          
          const currentContext = this.buildCurrentContext(state);
          const planningResult = await this.taskDynamicPlanningPhase(state, currentContext);
          
          if (planningResult.success && planningResult.adaptedSteps) {
            // ç”¨åŠ¨æ€è§„åˆ’çš„æ­¥éª¤æ›¿æ¢å‰©ä½™å·¥ä½œæµ
            const adaptedWorkflow = planningResult.adaptedSteps.map((adaptedStep, index) => ({
              ...adaptedStep,
              step: i + index + 1,
              status: 'pending' as const,
              attempts: 0,
              maxRetries: 2
            }));
            
            // æ›´æ–°å·¥ä½œæµï¼šä¿ç•™å·²å®Œæˆçš„æ­¥éª¤ï¼Œæ›¿æ¢å‰©ä½™æ­¥éª¤
            state.workflow = [
              ...state.workflow.slice(0, i + 1),
              ...adaptedWorkflow
            ];
            state.totalSteps = state.workflow.length;
            
            // ğŸ”§ ç§»é™¤workflow_adaptedäº‹ä»¶ï¼Œå‰ç«¯ä¸éœ€è¦
            
            logger.info(`âœ… Workflow adapted: ${adaptedWorkflow.length} new steps planned`);
          }
        }
        
        // ğŸ¯ ç›´æ¥å®Œæˆæ£€æµ‹ï¼šå¦‚æœåˆ¤æ–­ä»»åŠ¡å·²å®Œæˆï¼Œç«‹å³é€€å‡º
        if (!shouldContinue) {
          logger.info(`ğŸ Task completion detected, stopping workflow execution`);
          break;
        }
      }

      // ğŸ”§ æ£€æŸ¥å®ŒæˆçŠ¶æ€
      state.isComplete = state.completedSteps > 0; // è‡³å°‘æœ‰ä¸€æ­¥æˆåŠŸå°±ç®—éƒ¨åˆ†å®Œæˆ

      // ğŸ”§ ç”Ÿæˆæœ€ç»ˆç»“æœ
      const finalResult = this.generateWorkflowFinalResult(state);
      const overallSuccess = state.completedSteps > 0;
      
      // ğŸ”§ å‘é€generating_summaryäº‹ä»¶
      yield {
        event: 'generating_summary',
        data: {
          message: 'Generating summary...',
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ å‘é€workflow_completeäº‹ä»¶
      yield {
        event: 'workflow_complete',
        data: {
          message: 'Workflow completed',
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ å‘é€task_completeäº‹ä»¶
      yield {
        event: 'task_complete',
        data: {
          agentName: 'WorkflowEngine'
        }
      };

      // ğŸ”§ ä¿å­˜æœ€ç»ˆç»“æœ
      await this.saveWorkflowFinalResult(taskId, state, finalResult);

      return state.completedSteps > 0;

    } catch (error) {
      logger.error(`âŒ Enhanced workflow execution failed:`, error);
      
      yield {
        event: 'error',
        data: {
          message: 'Enhanced workflow execution failed',
          details: error instanceof Error ? error.message : String(error)
        }
      };

      return false;
    }
  }

  /**
   * å‡†å¤‡å·¥ä½œæµæ‰§è¡Œç¯å¢ƒ
   */
  private async prepareWorkflowExecution(taskId: string, state: EnhancedWorkflowState, mcpWorkflow: any): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (!task) {
        throw new Error('Task not found');
      }

      // ğŸ”§ ç¡®ä¿å·¥ä½œæµä¸­ç”¨åˆ°çš„MCPå·²è¿æ¥
      const requiredMCPs = [...new Set(state.workflow.map(step => step.mcp))];
      if (requiredMCPs.length > 0) {
        logger.info(`ğŸ“¡ Ensuring required MCPs are connected: ${requiredMCPs.join(', ')}`);
        await this.ensureWorkflowMCPsConnected(task.userId, taskId, requiredMCPs);
      }
    } catch (error) {
      logger.error('Failed to prepare workflow execution:', error);
      throw error;
    }
  }

  /**
   * ç¡®ä¿å·¥ä½œæµçš„MCPå·²è¿æ¥ - åŒæ­¥Agentå¼•æ“çš„å®Œæ•´æƒé™æ ¡éªŒé€»è¾‘
   */
  private async ensureWorkflowMCPsConnected(userId: string, taskId: string, mcpNames: string[]): Promise<void> {
    try {
      logger.info(`Ensuring MCP connections for workflow execution (User: ${userId}), required MCPs: ${mcpNames.join(', ')}`);

      // ğŸ”§ è·å–ä»»åŠ¡ä¿¡æ¯ä»¥è·å–å·¥ä½œæµMCPé…ç½®
      const task = await this.taskService.getTaskById(taskId);
      const mcpWorkflow = typeof task.mcpWorkflow === 'string' 
        ? JSON.parse(task.mcpWorkflow) 
        : task.mcpWorkflow;

      for (const mcpName of mcpNames) {
        try {
          logger.info(`ğŸ”— Ensuring MCP ${mcpName} is connected for workflow execution`);
          
          // æ£€æŸ¥MCPæ˜¯å¦å·²è¿æ¥
          const connectedMCPs = this.mcpManager.getConnectedMCPs(userId);
          const isConnected = connectedMCPs.some(mcp => mcp.name === mcpName);
          
          if (!isConnected) {
            logger.info(`MCP ${mcpName} not connected for user ${userId}, attempting to connect for workflow task...`);
            
            // ğŸ”§ è·å–MCPé…ç½®
            const { getPredefinedMCP } = await import('./predefinedMCPs.js');
            const mcpConfig = getPredefinedMCP(mcpName);
            
            if (!mcpConfig) {
              throw new Error(`MCP ${mcpName} configuration not found`);
            }

            // ğŸ”§ ä»å·¥ä½œæµä¸­æŸ¥æ‰¾MCPä¿¡æ¯ï¼ˆåŒæ­¥Agentå¼•æ“é€»è¾‘ï¼‰
            const mcpInfo = mcpWorkflow?.mcps?.find((mcp: any) => mcp.name === mcpName) || { name: mcpName, authRequired: mcpConfig.authRequired };

            let authenticatedMcpConfig = mcpConfig;

            // ğŸ”§ ä½¿ç”¨å·¥ä½œæµä¸­çš„authRequiredæ ‡è¯† - åŒæ­¥Agentå¼•æ“
            if (mcpInfo.authRequired) {
              // è·å–ç”¨æˆ·è®¤è¯ä¿¡æ¯
              const userAuth = await this.mcpAuthService.getUserMCPAuth(userId, mcpName);
              if (!userAuth || !userAuth.isVerified || !userAuth.authData) {
                throw new Error(`User authentication not found or not verified for MCP ${mcpName}. Please authenticate this MCP service first.`);
              }

              // åŠ¨æ€æ³¨å…¥è®¤è¯ä¿¡æ¯
              const dynamicEnv = { ...mcpConfig.env };
              if (mcpConfig.env) {
                for (const [envKey, envValue] of Object.entries(mcpConfig.env)) {
                  if ((!envValue || envValue === '') && userAuth.authData[envKey]) {
                    dynamicEnv[envKey] = userAuth.authData[envKey];
                    logger.info(`Injected authentication for ${envKey} in MCP ${mcpName} for user ${userId}`);
                  }
                }
              }

              // åˆ›å»ºå¸¦è®¤è¯ä¿¡æ¯çš„MCPé…ç½®
              authenticatedMcpConfig = {
                ...mcpConfig,
                env: dynamicEnv
              };
            } else {
              logger.info(`MCP ${mcpName} does not require authentication, using default configuration`);
            }

            // ğŸ”§ ä½¿ç”¨connectPredefinedæ–¹æ³•å®ç°å¤šç”¨æˆ·éš”ç¦»
            const connected = await this.mcpManager.connectPredefined(authenticatedMcpConfig, userId);
            if (!connected) {
              throw new Error(`Failed to connect to MCP ${mcpName} for user ${userId}`);
            }

            logger.info(`âœ… Successfully connected MCP ${mcpName} for user ${userId} and workflow task`);
          } else {
            logger.info(`âœ… MCP ${mcpName} already connected for user ${userId}`);
          }
        } catch (error) {
          logger.error(`Failed to ensure MCP connection for ${mcpName} (User: ${userId}):`, error);
          throw new Error(`Failed to connect required MCP service ${mcpName}: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
      }

      logger.info(`âœ… All required MCP services connected for workflow execution (User: ${userId})`);
    } catch (error) {
      logger.error('Failed to ensure workflow MCPs connected:', error);
      throw error;
    }
  }

  /**
   * å¸¦é‡è¯•æœºåˆ¶çš„æ­¥éª¤æ‰§è¡Œ
   */
  private async executeWorkflowStepWithRetry(step: WorkflowStep, state: EnhancedWorkflowState, input: any, actualToolName?: string): Promise<{
    success: boolean;
    result?: any;
    error?: string;
    actualArgs?: any;
  }> {
    let lastError = '';
    const toolName = actualToolName || step.action;
    
    for (let attempt = 1; attempt <= (step.maxRetries || 2) + 1; attempt++) {
      step.attempts = attempt;
      
      try {
        logger.info(`ğŸ”§ Executing ${step.mcp}.${toolName} (attempt ${attempt})`);
        
        const result = await this.executeWorkflowStep(step, state, input, actualToolName);
        
        if (result.success) {
          logger.info(`âœ… Step ${step.step} execution successful on attempt ${attempt}`);
          return result;
        } else {
          lastError = result.error || 'Unknown error';
          logger.warn(`âš ï¸ Step ${step.step} failed on attempt ${attempt}: ${lastError}`);
          
          if (attempt <= (step.maxRetries || 2)) {
            logger.info(`ğŸ”„ Retrying step ${step.step} (${attempt}/${step.maxRetries || 2})`);
            await new Promise(resolve => setTimeout(resolve, 1000 * attempt)); // é€’å¢å»¶è¿Ÿ
          }
        }
      } catch (error) {
        lastError = error instanceof Error ? error.message : String(error);
        logger.error(`âŒ Step ${step.step} execution error on attempt ${attempt}:`, error);
        
        if (attempt <= (step.maxRetries || 2)) {
          await new Promise(resolve => setTimeout(resolve, 1000 * attempt));
        }
      }
    }
    
    return { success: false, error: lastError };
  }

  /**
   * æ‰§è¡Œå•ä¸ªå·¥ä½œæµæ­¥éª¤
   */
  private async executeWorkflowStep(step: WorkflowStep, state: EnhancedWorkflowState, input: any, actualToolName?: string): Promise<{
    success: boolean;
    result?: any;
    error?: string;
    actualArgs?: any;
  }> {
    try {
      const task = await this.taskService.getTaskById(state.taskId);
      if (!task) {
        throw new Error('Task not found');
      }

      // ğŸ”§ æ”¯æŒLLMå·¥å…·å’ŒMCPå·¥å…·
      const isLLMTool = step.mcp === 'llm' || step.mcp.toLowerCase().includes('llm');
      
      if (isLLMTool) {
        // LLMå·¥å…·æ‰§è¡Œ
        const toolName = actualToolName || step.action;
        logger.info(`ğŸ¤– Calling LLM with action: ${toolName}`);
        logger.info(`ğŸ“ Input: ${JSON.stringify(input, null, 2)}`);
        
        const prompt = `Execute ${toolName} with the following input: ${JSON.stringify(input, null, 2)}`;
        const response = await this.llm.invoke([new SystemMessage(prompt)]);
        const result = response.content as string;
        
        logger.info(`âœ… LLM ${toolName} execution successful`);
        return { success: true, result, actualArgs: input };
      } else {
        // MCPå·¥å…·æ‰§è¡Œ - ä½¿ç”¨é¢„æ¨æ–­çš„å®é™…å·¥å…·åç§°
        let toolName = actualToolName;
        if (!toolName) {
          try {
            toolName = await this.inferActualToolName(step.mcp, step.action, input, task.userId);
          } catch (error) {
            const errorMessage = error instanceof Error ? error.message : String(error);
            logger.error(`âŒ Failed to infer tool name for MCP ${step.mcp} action ${step.action}: ${errorMessage}`);
            throw error;
          }
        }
        
        logger.info(`ğŸ“¡ Calling MCP ${step.mcp} with action: ${step.action} (resolved to: ${toolName})`);
        logger.info(`ğŸ“ Input: ${JSON.stringify(input, null, 2)}`);

        const result = await this.mcpToolAdapter.callTool(
          step.mcp,
          toolName,
          input,
          task.userId
        );

        logger.info(`âœ… MCP ${step.mcp} execution successful - returning original MCP structure`);
        return { success: true, result, actualArgs: input };
      }

    } catch (error) {
      logger.error(`âŒ Workflow step execution failed:`, error);
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }

  /**
   * ä»ä¸Šä¸‹æ–‡æ¨å¯¼æ­¥éª¤è¾“å…¥å‚æ•°
   */
  private inferStepInputFromContext(step: WorkflowStep, state: EnhancedWorkflowState): any {
    // åŸºäºä¸Šä¸€æ­¥çš„ç»“æœå’Œå½“å‰åŠ¨ä½œæ™ºèƒ½æ¨å¯¼å‚æ•°
    const lastResult = state.dataStore.lastResult;
    const action = step.action.toLowerCase();
    
    // ç®€å•çš„æ¨å¯¼é€»è¾‘ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ‰©å±•
    if (lastResult && typeof lastResult === 'object') {
      if (action.includes('tweet') && lastResult.text) {
        return { content: lastResult.text };
      }
      if (action.includes('search') && lastResult.query) {
        return { query: lastResult.query };
      }
      if (action.includes('get') && lastResult.id) {
        return { id: lastResult.id };
      }
    }
    
    return {};
  }

  /**
   * æ™ºèƒ½æ¨æ–­å®é™…å·¥å…·åç§°ï¼šä½¿ç”¨LLMå°†æè¿°æ€§æ–‡æœ¬è½¬æ¢ä¸ºå®é™…çš„MCPå·¥å…·åç§° (å‚è€ƒAgentå¼•æ“çš„é€šç”¨åšæ³•)
   */
  private async inferActualToolName(mcpName: string, action: string, input: any, userId: string): Promise<string> {
    try {
      // è·å–MCPçš„å¯ç”¨å·¥å…·åˆ—è¡¨
      const tools = await this.mcpManager.getTools(mcpName, userId);
      
      if (!tools || tools.length === 0) {
        logger.warn(`ğŸ” No tools found for MCP ${mcpName}, using original action: ${action}`);
        return action;
      }
      
      const toolNames = tools.map((tool: any) => tool.name);
      logger.info(`ğŸ” Available tools for ${mcpName}: ${toolNames.join(', ')}`);
      
      // 1. é¦–å…ˆæ£€æŸ¥actionæ˜¯å¦å·²ç»æ˜¯æœ‰æ•ˆçš„å·¥å…·åç§°
      if (toolNames.includes(action)) {
        logger.info(`âœ… Action "${action}" is already a valid tool name`);
        return action;
      }
      
      // 2. ä½¿ç”¨LLMè¿›è¡Œæ™ºèƒ½å·¥å…·åç§°æ¨æ–­ (é€šç”¨æ–¹æ³•ï¼Œå‚è€ƒAgentå¼•æ“)
      const toolInferencePrompt = `You are an expert tool name matcher. The requested action "${action}" needs to be mapped to an actual tool name from MCP service "${mcpName}".

CONTEXT:
- Requested action: ${action}
- Input parameters: ${JSON.stringify(input, null, 2)}
- MCP Service: ${mcpName}
- Available tools with descriptions:
${tools.map((tool: any) => {
  return `
Tool: ${tool.name}
Description: ${tool.description || 'No description'}
Input Schema: ${JSON.stringify(tool.inputSchema || {}, null, 2)}
`;
}).join('\n')}

MATCHING PRINCIPLES:
1. **Find functionally equivalent tool**: Select the tool that can accomplish the same objective as the requested action
2. **Consider semantic meaning**: Match based on functionality, not just text similarity
3. **Use exact tool names**: Return the exact tool name from the available list
4. **Prioritize best match**: Choose the most appropriate tool for the requested action

OUTPUT FORMAT:
Return a JSON object with exactly this structure:
{
  "toolName": "exact_tool_name_from_available_list",
  "reasoning": "why this tool was selected for the requested action"
}

Select the best matching tool now:`;

      const response = await this.llm.invoke([new SystemMessage(toolInferencePrompt)]);
      
      try {
        const responseText = response.content.toString().trim();
        logger.info(`ğŸ” === LLM Tool Inference Debug ===`);
        logger.info(`ğŸ” Original Action: ${action}`);
        logger.info(`ğŸ” Raw LLM Response: ${responseText}`);
        
        // ğŸ”§ ä½¿ç”¨Agentå¼•æ“ç›¸åŒçš„JSONæ¸…ç†é€»è¾‘
        let cleanedJson = responseText;
        
        // ç§»é™¤Markdownä»£ç å—æ ‡è®°
        cleanedJson = cleanedJson.replace(/```json\n?/g, '').replace(/```\n?/g, '');
        
        // ğŸ”§ ä½¿ç”¨Agentå¼•æ“çš„JSONæå–é€»è¾‘
        const extractedJson = this.extractCompleteJson(cleanedJson);
        if (extractedJson) {
          cleanedJson = extractedJson;
        }
        
        const inference = JSON.parse(cleanedJson);
        const selectedTool = inference.toolName;
        
        if (selectedTool && toolNames.includes(selectedTool)) {
          logger.info(`âœ… LLM selected tool: ${selectedTool} (${inference.reasoning})`);
          return selectedTool;
        } else {
          logger.warn(`âš ï¸ LLM selected invalid tool: ${selectedTool}, falling back to first available`);
        }
        
      } catch (parseError) {
        logger.error(`âŒ Failed to parse LLM tool inference response: ${response.content}`);
        logger.error(`âŒ Parse error: ${parseError}`);
      }
      
      // 3. å¦‚æœLLMæ¨æ–­å¤±è´¥ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå·¥å…·ä½œä¸ºé»˜è®¤å€¼
      if (toolNames.length > 0) {
        logger.warn(`ğŸ” Using first available tool as fallback: ${toolNames[0]}`);
        return toolNames[0];
      }
      
      // 4. æœ€åçš„fallback
      logger.warn(`ğŸ” No tools available for MCP ${mcpName}, using original action: ${action}`);
      return action;
      
    } catch (error) {
      logger.error(`âŒ Error inferring tool name for ${mcpName}.${action}:`, error);
      return action; // å¦‚æœæ¨æ–­å¤±è´¥ï¼Œè¿”å›åŸå§‹action
    }
  }

  /**
   * æå–å®Œæ•´JSONå¯¹è±¡ (ä»Agentå¼•æ“å¤åˆ¶)
   */
  private extractCompleteJson(text: string): string | null {
    // æŸ¥æ‰¾ç¬¬ä¸€ä¸ª '{' çš„ä½ç½®
    const startIndex = text.indexOf('{');
    if (startIndex === -1) {
      return null;
    }
    
    // ä» '{' å¼€å§‹ï¼Œæ‰‹åŠ¨åŒ¹é…å¤§æ‹¬å·ä»¥æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡
    let braceCount = 0;
    let inString = false;
    let escapeNext = false;
    
    for (let i = startIndex; i < text.length; i++) {
      const char = text[i];
      
      if (escapeNext) {
        escapeNext = false;
        continue;
      }
      
      if (char === '\\' && inString) {
        escapeNext = true;
        continue;
      }
      
      if (char === '"' && !escapeNext) {
        inString = !inString;
        continue;
      }
      
      if (!inString) {
        if (char === '{') {
          braceCount++;
        } else if (char === '}') {
          braceCount--;
          
          // å½“å¤§æ‹¬å·è®¡æ•°ä¸º0æ—¶ï¼Œæˆ‘ä»¬æ‰¾åˆ°äº†å®Œæ•´çš„JSONå¯¹è±¡
          if (braceCount === 0) {
            const jsonString = text.substring(startIndex, i + 1);
            logger.info(`ğŸ”§ Extracted complete JSON: ${jsonString}`);
            return jsonString;
          }
        }
      }
    }
    
    // å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´çš„JSONå¯¹è±¡ï¼Œè¿”å›null
    logger.warn(`âš ï¸ Could not find complete JSON object`);
    return null;
    }

  /**
   * ğŸ§  æ™ºèƒ½ä»»åŠ¡å¤æ‚åº¦åˆ†æï¼ˆé’ˆå¯¹ä»»åŠ¡å¼•æ“ä¼˜åŒ–ï¼‰
   */
  private async analyzeTaskComplexity(
    query: string, 
    workflowSteps: number
  ): Promise<{
    type: 'simple_query' | 'medium_task' | 'complex_workflow';
    recommendedObservation: 'fast' | 'balanced' | 'thorough';
    shouldCompleteEarly: boolean;
    reasoning: string;
  }> {
    try {
      // ğŸ” åŸºäºæ¨¡å¼çš„å¿«é€Ÿåˆ†æ
      const quickAnalysis = this.quickTaskComplexityAnalysis(query, workflowSteps);
      if (quickAnalysis) {
        return quickAnalysis;
      }

      // ğŸ§  LLMæ·±åº¦åˆ†æï¼ˆç”¨äºè¾¹ç¼˜æƒ…å†µï¼‰
      const analysisPrompt = `Analyze the task complexity for workflow execution and recommend observation strategy.

**User Query**: "${query}"
**Workflow Steps**: ${workflowSteps} steps

**Task Types:**
1. **SIMPLE_QUERY** (Direct data requests):
   - "Show me...", "Get current...", "What is..."
   - Single data point requests
   - Basic information lookup
   - Observation: Fast - complete after first success

2. **MEDIUM_TASK** (Multi-step operations):
   - "Compare X and Y", "Analyze trends"
   - Data processing and basic analysis
   - Sequential operations with dependencies
   - Observation: Balanced - observe key checkpoints

3. **COMPLEX_WORKFLOW** (Comprehensive tasks):
   - Multi-source analysis with transformations
   - Complex decision workflows
   - Extensive data processing chains
   - Observation: Thorough - observe every step

**OUTPUT FORMAT (JSON only):**
{
  "type": "simple_query|medium_task|complex_workflow",
  "recommended_observation": "fast|balanced|thorough",
  "should_complete_early": true/false,
  "reasoning": "Brief explanation of complexity assessment"
}`;

      const response = await this.llm.invoke([new SystemMessage(analysisPrompt)]);
      const content = response.content as string;
      
      // è§£æLLMå“åº”
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        const parsed = JSON.parse(jsonMatch[0]);
        return {
          type: parsed.type || 'medium_task',
          recommendedObservation: parsed.recommended_observation || 'balanced',
          shouldCompleteEarly: parsed.should_complete_early || false,
          reasoning: parsed.reasoning || 'LLM analysis completed'
        };
      }
    } catch (error) {
      logger.warn(`Task complexity analysis failed: ${error}`);
    }

    // é»˜è®¤ä¸­ç­‰å¤æ‚åº¦
    return {
      type: 'medium_task',
      recommendedObservation: 'balanced',
      shouldCompleteEarly: false,
      reasoning: 'Default complexity analysis'
    };
  }

  /**
   * ğŸ” å¿«é€Ÿæ¨¡å¼åŒ¹é…å¤æ‚åº¦åˆ†æï¼ˆé’ˆå¯¹ä»»åŠ¡å¼•æ“ï¼‰
   */
  private quickTaskComplexityAnalysis(
    query: string, 
    workflowSteps: number
  ): {
    type: 'simple_query' | 'medium_task' | 'complex_workflow';
    recommendedObservation: 'fast' | 'balanced' | 'thorough';
    shouldCompleteEarly: boolean;
    reasoning: string;
  } | null {
    const lowerQuery = query.toLowerCase().trim();

    // ğŸŸ¢ ç®€å•æŸ¥è¯¢æ¨¡å¼ (1-2 steps, fast completion)
    const simplePatterns = [
      /^(show me|get|fetch|what is|current|latest)\s/,
      /^(how much|how many|price of|value of)\s/,
      /^(status of|info about|details of)\s/,
      /\b(index|price|value|status|information)\s*(of|for)?\s*\w+$/,
      /^(get current|show current|fetch latest)\s/
    ];

    if (simplePatterns.some(pattern => pattern.test(lowerQuery)) || workflowSteps <= 2) {
      return {
        type: 'simple_query',
        recommendedObservation: 'fast',
        shouldCompleteEarly: true,
        reasoning: 'Direct data query - fast completion after first success'
      };
    }

    // ğŸŸ¡ ä¸­ç­‰ä»»åŠ¡æ¨¡å¼ (3-5 steps, balanced observation)
    const mediumPatterns = [
      /\b(compare|analyze|calculate|process)\b/,
      /\b(then|after|next|followed by)\b/,
      /\b(both|all|multiple|several)\b/,
      /\band\s+\w+\s+(also|too|as well)/,
      /\b(summary|report|overview)\b/
    ];

    if (mediumPatterns.some(pattern => pattern.test(lowerQuery)) || (workflowSteps >= 3 && workflowSteps <= 5)) {
      return {
        type: 'medium_task',
        recommendedObservation: 'balanced',
        shouldCompleteEarly: false,
        reasoning: 'Multi-step task requiring balanced observation'
      };
    }

    // ğŸ”´ å¤æ‚å·¥ä½œæµæ¨¡å¼ (6+ steps, thorough observation)
    const complexPatterns = [
      /\b(workflow|pipeline|process.*step)\b/,
      /\b(first.*then.*finally|step.*step.*step)\b/,
      /\b(comprehensive|detailed|thorough)\s+(analysis|report|study)\b/,
      /\b(multiple.*and.*then)\b/,
      /\b(optimize|automate|integrate)\b/
    ];

    if (complexPatterns.some(pattern => pattern.test(lowerQuery)) || workflowSteps > 5 || lowerQuery.length > 100) {
      return {
        type: 'complex_workflow',
        recommendedObservation: 'thorough',
        shouldCompleteEarly: false,
        reasoning: 'Complex multi-step workflow requiring thorough observation'
      };
    }

    return null; // éœ€è¦LLMæ·±åº¦åˆ†æ
  }

/**
 * ğŸ§  æ–°å¢ï¼šåŠ¨æ€è§„åˆ’é˜¶æ®µï¼ˆå‚è€ƒAgentå¼•æ“ï¼Œä½¿ä»»åŠ¡å¼•æ“ä¹Ÿå…·å¤‡æ™ºèƒ½è§„åˆ’èƒ½åŠ›ï¼‰
 */
private async taskDynamicPlanningPhase(
  state: EnhancedWorkflowState,
  currentContext: string
): Promise<{
  success: boolean;
  adaptedSteps?: Array<{
    step: number;
    mcp: string;
    action: string;
    input?: any;
    reasoning?: string;
  }>;
  error?: string;
}> {
  try {
    // ğŸ”§ è·å–å½“å‰å¯ç”¨çš„MCPå’Œæ‰§è¡Œå†å²
    const availableMCPs = await this.getAvailableMCPsForPlanning(state.taskId);
    const executionHistory = this.buildExecutionHistory(state);
    
    const plannerPrompt = this.buildTaskPlannerPrompt(state, availableMCPs, currentContext, executionHistory);

    // ğŸ”„ ä½¿ç”¨LLMè¿›è¡ŒåŠ¨æ€è§„åˆ’
    const response = await this.llm.invoke([new SystemMessage(plannerPrompt)]);
    const adaptedSteps = this.parseTaskPlan(response.content.toString());

    return { success: true, adaptedSteps };
  } catch (error) {
    logger.error('Task dynamic planning failed:', error);
    return { 
      success: false, 
      error: error instanceof Error ? error.message : String(error) 
    };
  }
}

/**
 * ğŸ§  æ–°å¢ï¼šä»»åŠ¡è§‚å¯Ÿé˜¶æ®µï¼ˆå‚è€ƒAgentå¼•æ“ï¼Œæ™ºèƒ½åˆ†æå½“å‰è¿›åº¦å’Œè°ƒæ•´ç­–ç•¥ï¼‰
 */
private async taskObservationPhase(
  state: EnhancedWorkflowState,
  taskComplexity?: { type: string; recommendedObservation: string; shouldCompleteEarly: boolean; reasoning: string }
): Promise<{
  shouldContinue: boolean;
  shouldAdaptWorkflow: boolean;
  adaptationReason?: string;
  newObjective?: string;
}> {
  try {
    const observerPrompt = this.buildTaskObserverPrompt(state, taskComplexity);
    const response = await this.llm.invoke([new SystemMessage(observerPrompt)]);
    
    return this.parseTaskObservation(response.content.toString());
  } catch (error) {
    logger.error('Task observation failed:', error);
    return { 
      shouldContinue: true, 
      shouldAdaptWorkflow: false 
    };
  }
}

/**
 * ğŸ”§ æ„å»ºä»»åŠ¡è§„åˆ’æç¤ºè¯
 */
private buildTaskPlannerPrompt(
  state: EnhancedWorkflowState,
  availableMCPs: any[],
  currentContext: string,
  executionHistory: string
): string {
  return `You are an intelligent task workflow planner. Based on the current execution context and available tools, dynamically plan the optimal next steps.

**Current Task**: ${state.originalQuery}

**Execution Context**: ${currentContext}

**Available MCP Tools**:
${JSON.stringify(availableMCPs.map(mcp => ({
  name: mcp.name,
  description: mcp.description,
  capabilities: mcp.predefinedTools?.map((tool: any) => tool.name) || []
})), null, 2)}

**Previous Execution History**:
${executionHistory}

**Current Workflow Progress**: ${state.completedSteps}/${state.totalSteps} steps completed

**Instructions**:
1. Analyze what has been accomplished so far
2. Identify what still needs to be done to complete the original task
3. Plan the optimal next steps using available MCP tools
4. Consider efficiency and logical flow
5. Adapt based on previous results

Respond with valid JSON in this exact format:
{
  "analysis": "Brief analysis of current progress and what's needed",
  "adapted_steps": [
    {
      "step": 1,
      "mcp": "mcp_name",
      "action": "Clear description of what this step will accomplish",
      "input": {"actual": "parameters"},
      "reasoning": "Why this step is needed now"
    }
  ],
  "planning_reasoning": "Detailed explanation of the planning logic"
}`;
}

/**
 * ğŸ”§ æ„å»ºä»»åŠ¡è§‚å¯Ÿæç¤ºè¯ï¼ˆæ™ºèƒ½å¤æ‚åº¦æ„ŸçŸ¥ï¼‰
 */
private buildTaskObserverPrompt(
  state: EnhancedWorkflowState,
  taskComplexity?: { type: string; recommendedObservation: string; shouldCompleteEarly: boolean; reasoning: string }
): string {
  const completedStepsInfo = state.executionHistory
    .filter(step => step.success)
    .map(step => `Step ${step.stepNumber}: ${step.action} -> Success`)
    .join('\n');
    
  const failedStepsInfo = state.executionHistory
    .filter(step => !step.success)
    .map(step => `Step ${step.stepNumber}: ${step.action} -> Failed: ${step.error}`)
    .join('\n');

  return `You are an intelligent task execution observer analyzing workflow progress. Make smart decisions based on task complexity.

**Original Task**: ${state.originalQuery}
**Task Complexity**: ${taskComplexity ? `${taskComplexity.type} (${taskComplexity.recommendedObservation} observation)` : 'Unknown'}

**Current Progress**: Step ${state.currentStepIndex + 1}/${state.totalSteps} (${Math.round(((state.currentStepIndex + 1) / state.totalSteps) * 100)}%)

**COMPLEXITY-BASED COMPLETION CRITERIA**:

${taskComplexity?.type === 'simple_query' ? `
ğŸŸ¢ **SIMPLE QUERY MODE** - Fast completion priority:
- âœ… **COMPLETE IMMEDIATELY** if first step returned valid data
- âœ… **COMPLETE IMMEDIATELY** if user's question is answered
- âŒ Continue only if NO data retrieved or complete failure
- ğŸ¯ Priority: Speed over perfection for data requests
` : taskComplexity?.type === 'medium_task' ? `
ğŸŸ¡ **MEDIUM TASK MODE** - Balanced approach:
- âœ… Complete if main objectives achieved (50%+ steps successful)
- âœ… Complete if sufficient data collected for analysis
- âŒ Continue if key analysis or comparison still needed
- ğŸ¯ Priority: Balance speed with thoroughness
` : `
ğŸ”´ **COMPLEX WORKFLOW MODE** - Thorough completion:
- âœ… Complete only if all major workflow components finished
- âœ… Complete if comprehensive analysis delivered
- âŒ Continue if significant workflow steps remain
- ğŸ¯ Priority: Comprehensive completion over speed
`}

**Execution Summary**:
- Completed Steps: ${state.completedSteps}
- Failed Steps: ${state.failedSteps}
- Current Step: ${state.currentStepIndex + 1}

**Recent Completed Steps**:
${completedStepsInfo || 'None yet'}

**Recent Failed Steps**:
${failedStepsInfo || 'None'}

**Available Results & Data**:
${JSON.stringify(state.dataStore, null, 2)}

**Observation Guidelines**:
1. **Task Completion Analysis**: Evaluate if the original task objective has been achieved with current results
2. **Progress Assessment**: Consider the quality and relevance of completed steps
3. **Failure Impact**: Assess how failed steps affect overall task completion
4. **Workflow Efficiency**: Determine if the remaining planned steps are still optimal
5. **Early Completion**: Identify if sufficient results exist to complete the task early
6. **Adaptation Needs**: Detect if the workflow should be adapted based on current context

**Decision Criteria**:
- CONTINUE: Task not complete, current workflow is optimal
- STOP EARLY: Task objective achieved with current results
- ADAPT: Task not complete, but workflow needs modification

Respond with valid JSON:
{
  "should_continue": true/false,
  "should_adapt_workflow": true/false,
  "adaptation_reason": "Reason for adaptation if needed",
  "new_objective": "Adjusted objective if adaptation needed",
  "completion_analysis": "Analysis of current task completion status",
  "confidence_score": 0.0-1.0,
  "observation_reasoning": "Detailed step-by-step reasoning for this decision"
}`;
}

/**
 * ğŸ”§ è§£æä»»åŠ¡è§„åˆ’ç»“æœ
 */
private parseTaskPlan(content: string): Array<{
  step: number;
  mcp: string;
  action: string;
  input?: any;
  reasoning?: string;
}> {
  try {
    const cleanedContent = content
      .replace(/```json\s*/g, '')
      .replace(/```\s*$/g, '')
      .trim();
    
    const parsed = JSON.parse(cleanedContent);
    return parsed.adapted_steps || [];
  } catch (error) {
    logger.error('Failed to parse task plan:', error);
    return [];
  }
}

/**
 * ğŸ”§ è§£æä»»åŠ¡è§‚å¯Ÿç»“æœ
 */
private parseTaskObservation(content: string): {
  shouldContinue: boolean;
  shouldAdaptWorkflow: boolean;
  adaptationReason?: string;
  newObjective?: string;
} {
  try {
    const cleanedContent = content
      .replace(/```json\s*/g, '')
      .replace(/```\s*$/g, '')
      .trim();
    
    const parsed = JSON.parse(cleanedContent);
    
    return {
      shouldContinue: parsed.should_continue !== false,
      shouldAdaptWorkflow: parsed.should_adapt_workflow === true,
      adaptationReason: parsed.adaptation_reason,
      newObjective: parsed.new_objective
    };
  } catch (error) {
    logger.error('Failed to parse task observation:', error);
    logger.error('Raw observation content:', content);
    return { 
      shouldContinue: true, 
      shouldAdaptWorkflow: false 
    };
  }
}

/**
 * ğŸ”§ è·å–å¯ç”¨äºè§„åˆ’çš„MCPåˆ—è¡¨
 */
private async getAvailableMCPsForPlanning(taskId: string): Promise<any[]> {
  try {
    const task = await this.taskService.getTaskById(taskId);
    if (task?.mcpWorkflow?.mcps) {
      return task.mcpWorkflow.mcps;
    }
    return [];
  } catch (error) {
    logger.error('Failed to get available MCPs for planning:', error);
    return [];
  }
}

  /**
   * ğŸ”§ æ„å»ºæ‰§è¡Œå†å²æ‘˜è¦
   */
  private buildExecutionHistory(state: EnhancedWorkflowState): string {
    if (state.executionHistory.length === 0) {
      return 'No previous execution history.';
    }
    
    return state.executionHistory
      .map(step => `Step ${step.stepNumber}: ${step.action} -> ${step.success ? 'Success' : 'Failed'}`)
      .join('\n');
  }

  /**
   * ğŸ”§ æ„å»ºå½“å‰æ‰§è¡Œä¸Šä¸‹æ–‡
   */
  private buildCurrentContext(state: EnhancedWorkflowState): string {
    const completedSteps = state.executionHistory.filter(step => step.success);
    const failedSteps = state.executionHistory.filter(step => !step.success);
    
    let context = `Current execution context for task: ${state.originalQuery}\n\n`;
    
    // è¿›åº¦æ¦‚è§ˆ
    context += `Progress Overview:\n`;
    context += `- Completed: ${state.completedSteps}/${state.totalSteps} steps\n`;
    context += `- Failed: ${state.failedSteps} steps\n`;
    context += `- Current step index: ${state.currentStepIndex}\n\n`;
    
    // å·²å®Œæˆçš„æ­¥éª¤å’Œç»“æœ
    if (completedSteps.length > 0) {
      context += `Successfully completed steps:\n`;
      completedSteps.forEach(step => {
        const resultSummary = typeof step.result === 'string' 
          ? step.result.substring(0, 100) + '...'
          : JSON.stringify(step.result).substring(0, 100) + '...';
        context += `- Step ${step.stepNumber}: ${step.action} -> ${resultSummary}\n`;
      });
      context += '\n';
    }
    
    // å¤±è´¥çš„æ­¥éª¤
    if (failedSteps.length > 0) {
      context += `Failed steps:\n`;
      failedSteps.forEach(step => {
        context += `- Step ${step.stepNumber}: ${step.action} -> Error: ${step.error}\n`;
      });
      context += '\n';
    }
    
    // å¯ç”¨æ•°æ®
    if (Object.keys(state.dataStore).length > 0) {
      context += `Available data in context:\n`;
      Object.keys(state.dataStore).forEach(key => {
        context += `- ${key}: ${typeof state.dataStore[key]}\n`;
      });
    }
    
    return context;
  }

/**
 * ğŸ”§ æ–°å¢ï¼šæµå¼æ ¼å¼åŒ–ä»»åŠ¡ç»“æœï¼ˆå‚è€ƒAgentå¼•æ“å®ç°ï¼‰
 */
  private async *formatAndStreamTaskResult(
    rawResult: any,
    mcpName: string,
    toolName: string
  ): AsyncGenerator<string, void, unknown> {
    try {
      // ğŸ”§ çº¯ç²¹çš„æ ¼å¼è½¬æ¢ï¼šJSON â†’ Markdownï¼ˆæ™ºèƒ½é•¿åº¦æ§åˆ¶ï¼‰
      const dataString = typeof rawResult === 'string' ? rawResult : JSON.stringify(rawResult, null, 2);
      const isLongData = dataString.length > 3000; // è¶…è¿‡3000å­—ç¬¦è®¤ä¸ºæ˜¯é•¿æ•°æ®
      
      const formatPrompt = `Convert this JSON data to clean, readable Markdown format. Output the formatted Markdown directly without any code blocks or wrappers.

**Data to format:**
${dataString}

**Formatting rules:**
- Convert JSON structure to clear Markdown
- Use tables for object data when helpful
- Use lists for arrays
- Make long numbers readable with commas
- Output the formatted Markdown directly
- DO NOT wrap in code blocks or backticks
- DO NOT add explanations or descriptions

${isLongData ? `
**IMPORTANT - Data Length Control:**
This is a large dataset. Apply smart filtering:
- Show only the most important/commonly used fields
- For blockchain data: show hash, number, gasUsed, gasLimit, miner, timestamp, parentHash
- Skip verbose fields like logsBloom, extraData, mix_hash unless they contain short meaningful values
- For large objects: show top 10-15 most relevant fields
- Always prioritize user-actionable or identifying information
- Keep the output concise and focused
` : `
**Standard formatting:**
- Keep ALL original data values
- Format all available fields
`}
- ONLY return the formatted data`;


      // ä½¿ç”¨æµå¼LLMç”Ÿæˆæ ¼å¼åŒ–ç»“æœ
      const stream = await this.llm.stream([new SystemMessage(formatPrompt)]);

      for await (const chunk of stream) {
        if (chunk.content) {
          yield chunk.content as string;
        }
      }
    } catch (error) {
      logger.error(`Failed to format task result:`, error);
      // é™çº§å¤„ç†ï¼šè¿”å›åŸºæœ¬æ ¼å¼åŒ–
      const fallbackResult = `### ${toolName} æ‰§è¡Œç»“æœ\n\n\`\`\`json\n${JSON.stringify(rawResult, null, 2)}\n\`\`\``;
      yield fallbackResult;
    }
  }

  /**
   * ç”Ÿæˆæ ¼å¼åŒ–ç»“æœï¼ˆéæµå¼ï¼Œç”¨äºå­˜å‚¨ï¼‰
   */
  private async generateFormattedResult(rawResult: any, mcpName: string, action: string): Promise<string> {
    try {
      const dataString = JSON.stringify(rawResult, null, 2);
      // ğŸ”§ ç§»é™¤é•¿æ•°æ®åˆ¤æ–­é™åˆ¶ï¼Œå…è®¸å¤„ç†ä»»æ„é•¿åº¦çš„æ•°æ®
      const isLongData = false; // dataString.length > 3000; // ç§»é™¤3000å­—ç¬¦é™åˆ¶
      
      const prompt = `Convert this JSON data to clean, readable Markdown format. Output the formatted Markdown directly without any code blocks or wrappers.

**Data to format:**
${dataString}

**Formatting rules:**
- Convert JSON structure to clear Markdown
- Use tables for object data when helpful
- Use lists for arrays
- Make long numbers readable with commas
- Output the formatted Markdown directly
- DO NOT wrap in code blocks or backticks
- DO NOT add explanations or descriptions

${isLongData ? `
**IMPORTANT - Data Length Control:**
This is a large dataset. Apply smart filtering:
- Show only the most important/commonly used fields
- For blockchain data: show hash, number, gasUsed, gasLimit, miner, timestamp, parentHash
- Skip verbose fields like logsBloom, extraData, mix_hash unless they contain short meaningful values
- For large objects: show top 10-15 most relevant fields
- Always prioritize user-actionable or identifying information
- Keep the output concise and focused
` : `
**Standard formatting:**
- Keep ALL original data values
- Format all available fields
`}
- ONLY return the formatted data`;

      const response = await this.llm.invoke([new SystemMessage(prompt)]);
      return response.content as string;
    } catch (error) {
      logger.error('Failed to format result:', error);
      return JSON.stringify(rawResult, null, 2);
    }
  }

  /**
   * æ£€æŸ¥æ˜¯å¦ä¸ºMCPè¿æ¥é”™è¯¯
   */
  private isMCPConnectionError(error: string): boolean {
    const lowerError = error.toLowerCase();
    return lowerError.includes('mcp') || 
           lowerError.includes('connection') || 
           lowerError.includes('auth') ||
           lowerError.includes('not connected');
  }

  /**
   * ç”Ÿæˆå·¥ä½œæµæœ€ç»ˆç»“æœ
   */
  private generateWorkflowFinalResult(state: EnhancedWorkflowState): string {
    const successRate = Math.round((state.completedSteps / state.totalSteps) * 100);
    
    let summary = `Workflow execution completed with ${successRate}% success rate.\n\n`;
    summary += `**Execution Summary:**\n`;
    summary += `- Total Steps: ${state.totalSteps}\n`;
    summary += `- Completed: ${state.completedSteps}\n`;
    summary += `- Failed: ${state.failedSteps}\n\n`;
    
    if (state.completedSteps > 0) {
      summary += `**Successful Steps:**\n`;
      state.executionHistory
        .filter(entry => entry.success)
        .forEach(entry => {
          summary += `- Step ${entry.stepNumber}: ${entry.mcpName}.${entry.action} âœ…\n`;
        });
    }
    
    if (state.failedSteps > 0) {
      summary += `\n**Failed Steps:**\n`;
      state.executionHistory
        .filter(entry => !entry.success)
        .forEach(entry => {
          summary += `- Step ${entry.stepNumber}: ${entry.mcpName}.${entry.action} âŒ (${entry.error})\n`;
        });
    }
    
    return summary;
  }



  /**
   * ä¿å­˜æ­¥éª¤åŸå§‹ç»“æœæ¶ˆæ¯
   */
  private async saveStepRawResult(taskId: string, stepNumber: number, step: WorkflowStep, rawResult: any, actualArgs: any, toolType: string, mcpName: string | null, expectedOutput: string, reasoning: string, actualToolName?: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„contentæ ¼å¼å’Œmetadataç»“æ„
        const toolName = actualToolName || step.action;
        const rawContent = `WorkflowEngine Step ${stepNumber} Raw Result: ${toolName}

${JSON.stringify(rawResult, null, 2)}`;

        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: rawContent,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.EXECUTION,
            stepNumber: stepNumber,
            stepName: toolName,
            taskPhase: 'execution',
            contentType: 'raw_result',
            agentName: 'WorkflowEngine',
            isComplete: true,
            toolDetails: {
              toolType: toolType,
              toolName: toolName,
              mcpName: mcpName,
              args: actualArgs || step.input || {},
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            },
            executionDetails: {
              rawResult: rawResult,
              success: true,
              processingInfo: {
                originalDataSize: JSON.stringify(rawResult).length,
                processingTime: new Date().toISOString()
              }
            }
          }
        });

        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error(`Failed to save workflow step raw result:`, error);
    }
  }

  /**
   * ä¿å­˜æ­¥éª¤æ ¼å¼åŒ–ç»“æœæ¶ˆæ¯
   */
  private async saveStepFormattedResult(taskId: string, stepNumber: number, step: WorkflowStep, formattedResult: string, actualArgs: any, toolType: string, mcpName: string | null, expectedOutput: string, reasoning: string, actualToolName?: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        // ğŸ”§ ä¸Agentå¼•æ“å®Œå…¨ä¸€è‡´çš„contentæ ¼å¼å’Œmetadataç»“æ„
        const toolName = actualToolName || step.action;
        const resultType = toolType === 'llm' ? 'LLM Result' : 'Formatted Result';
        const formattedContent = `WorkflowEngine Step ${stepNumber} ${resultType}: ${toolName}

${formattedResult}`;

        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: formattedContent,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.EXECUTION,
            stepNumber: stepNumber,
            stepName: toolName,
            taskPhase: 'execution',
            contentType: 'formatted_result',
            agentName: 'WorkflowEngine',
            isComplete: true,
            toolDetails: {
              toolType: toolType,
              toolName: toolName,
              mcpName: mcpName,
              args: actualArgs || step.input || {},
              expectedOutput: expectedOutput,
              reasoning: reasoning,
              timestamp: new Date().toISOString()
            },
            executionDetails: {
              formattedResult: formattedResult,
              success: true,
              processingInfo: {
                formattedDataSize: formattedResult.length,
                processingTime: new Date().toISOString()
              }
            }
          }
        });

        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error(`Failed to save workflow step formatted result:`, error);
    }
  }

  /**
   * ä¿å­˜ä»»åŠ¡æœ€ç»ˆç»“æœ
   */
  private async saveWorkflowFinalResult(taskId: string, state: EnhancedWorkflowState, finalResult: string): Promise<void> {
    try {
      const task = await this.taskService.getTaskById(taskId);
      if (task.conversationId) {
        await messageDao.createMessage({
          conversationId: task.conversationId,
          content: `Workflow Final Result:\n\n${finalResult}`,
          type: MessageType.ASSISTANT,
          intent: MessageIntent.TASK,
          taskId,
          metadata: {
            stepType: MessageStepType.SUMMARY,
            stepName: 'Workflow Completion',
            taskPhase: 'completion',
            isComplete: true,
            executionSummary: {
              totalSteps: state.totalSteps,
              completedSteps: state.completedSteps,
              failedSteps: state.failedSteps,
              successRate: Math.round((state.completedSteps / state.totalSteps) * 100)
            }
          }
        });
        await conversationDao.incrementMessageCount(task.conversationId);
      }
    } catch (error) {
      logger.error('Failed to save workflow final result:', error);
    }
  }

  /**
   * ğŸ¯ æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²æ”¶é›†è¶³å¤Ÿæ•°æ®ï¼ˆå‚è€ƒAgentå¼•æ“çš„ç›´æ¥åˆ¤æ–­æ–¹æ³•ï¼‰
   */
  private async hasTaskCollectedSufficientData(state: EnhancedWorkflowState): Promise<boolean> {
    // åŸºäºæ•°æ®å­˜å‚¨å’Œæ‰§è¡Œå†å²çš„å¿«é€Ÿåˆ¤æ–­
    const hasSuccessfulSteps = state.completedSteps > 0;
    const hasUsefulData = Object.keys(state.dataStore).length > 1; // é™¤äº† lastResult è¿˜æœ‰å…¶ä»–æ•°æ®
    
    return hasSuccessfulSteps && hasUsefulData;
  }

  /**
   * ğŸ¯ å¿«é€Ÿä»»åŠ¡å®Œæˆæ£€æŸ¥ï¼ˆå‚è€ƒAgentå¼•æ“çš„ç®€åŒ–åˆ¤æ–­é€»è¾‘ï¼‰
   */
  private async quickTaskCompletionCheck(
    state: EnhancedWorkflowState, 
    taskComplexity: { type: string; recommendedObservation: string; shouldCompleteEarly: boolean; reasoning: string }
  ): Promise<boolean> {
    // ç®€åŒ–çš„å®Œæˆåˆ¤æ–­é€»è¾‘
    try {
      const successfulSteps = state.executionHistory.filter(step => step.success);
      
      // åŸºäºä»»åŠ¡å¤æ‚åº¦çš„å¿«é€Ÿåˆ¤æ–­
      if (taskComplexity.type === 'simple_query') {
        // ç®€å•æŸ¥è¯¢ï¼šæœ‰æ•°æ®å°±å®Œæˆ
        return successfulSteps.length > 0;
      } else if (taskComplexity.type === 'medium_task') {
        // ä¸­ç­‰ä»»åŠ¡ï¼šè‡³å°‘å®Œæˆä¸€åŠæ­¥éª¤æˆ–æœ‰è¶³å¤Ÿæ•°æ®
        const completionRatio = state.completedSteps / state.totalSteps;
        return completionRatio >= 0.5 || successfulSteps.length >= 2;
      } else {
        // å¤æ‚å·¥ä½œæµï¼šéœ€è¦æ›´å¤šæ­¥éª¤å®Œæˆ
        const completionRatio = state.completedSteps / state.totalSteps;
        return completionRatio >= 0.7;
      }
    } catch (error) {
      logger.error('Quick task completion check failed:', error);
      return true; // é»˜è®¤ç»§ç»­æ‰§è¡Œ
    }
  }

  /**
   * ğŸ¯ ç®€åŒ–çš„å·¥ä½œæµé€‚åº”åˆ¤æ–­ï¼ˆå‡å°‘å¤æ‚åº¦ï¼‰
   */
  private async shouldAdaptWorkflow(state: EnhancedWorkflowState, currentStep: WorkflowStep): Promise<boolean> {
    // ç®€åŒ–çš„é€‚åº”åˆ¤æ–­ï¼šåªåœ¨è¿ç»­å¤±è´¥æ—¶é€‚åº”
    const recentFailures = state.executionHistory
      .slice(-2) // æœ€è¿‘2æ­¥
      .filter(step => !step.success);
    
    return recentFailures.length >= 2; // è¿ç»­2æ­¥å¤±è´¥æ‰é€‚åº”
  }


}

/**
 * å¢å¼ºçš„æ™ºèƒ½TaskæœåŠ¡ - åŸºäºå·¥ä½œæµæ‰§è¡Œ
 */
export class EnhancedIntelligentTaskService {
  private engine: EnhancedIntelligentTaskEngine;
  private taskService: any;

  constructor() {
    this.engine = new EnhancedIntelligentTaskEngine();
    this.taskService = getTaskService();
  }

  /**
   * æ‰§è¡Œå¢å¼ºçš„æ™ºèƒ½Task - åŸºäºå·²æ„å»ºçš„å·¥ä½œæµ
   */
  async executeTaskEnhanced(
    taskId: string,
    stream: (data: any) => void,
    skipAnalysisCheck: boolean = false
  ): Promise<boolean> {
    try {
      logger.info(`âš¡ Starting enhanced workflow-based task execution [Task: ${taskId}]`);

      // è·å–ä»»åŠ¡ä¿¡æ¯
      const task = await this.taskService.getTaskById(taskId);
      if (!task) {
        // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
        stream({ 
          event: 'error', 
          data: { 
            message: 'Task not found'
          }
        });
        return false;
      }

      // æ£€æŸ¥æ˜¯å¦å·²æœ‰å·¥ä½œæµ
      const mcpWorkflow = typeof task.mcpWorkflow === 'string' 
        ? JSON.parse(task.mcpWorkflow) 
        : task.mcpWorkflow;

      if (!skipAnalysisCheck && (!mcpWorkflow || !mcpWorkflow.workflow || mcpWorkflow.workflow.length === 0)) {
        // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
        stream({ 
          event: 'error', 
          data: { 
            message: 'No workflow found. Please analyze the task first.',
            details: 'Call /api/task/:id/analyze to generate a workflow before execution.'
          }
        });
        return false;
      }

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await taskExecutorDao.updateTaskStatus(taskId, 'in_progress');
      // ğŸ”§ å‘é€çŠ¶æ€æ›´æ–°äº‹ä»¶
      stream({ 
        event: 'status_update', 
        data: { 
          status: 'in_progress'
        }
      });

      // ä½¿ç”¨å¢å¼ºå¼•æ“æ‰§è¡Œå·¥ä½œæµ
      const executionGenerator = this.engine.executeWorkflowEnhanced(taskId, mcpWorkflow);

      let finalSuccess = false;

      for await (const result of executionGenerator) {
        // ğŸ”§ ç›´æ¥æµå¼ä¼ è¾“åŸå§‹äº‹ä»¶ï¼Œä¸åŒ…è£…
        stream(result);
        
        // è®°å½•æœ€ç»ˆæ‰§è¡Œç»“æœ
        if (result.event === 'final_result') {
          finalSuccess = result.data.success;
        }
      }

      // æ›´æ–°ä»»åŠ¡çŠ¶æ€
      await taskExecutorDao.updateTaskStatus(
        taskId, 
        finalSuccess ? 'completed' : 'failed'
      );

      // ğŸ”§ å‘é€æ‰§è¡Œå®Œæˆäº‹ä»¶
      stream({
        event: 'task_execution_complete',
        data: {
          success: finalSuccess,
          message: finalSuccess ? 
            'Task execution completed successfully' : 
            'Task execution failed'
        }
      });

      logger.info(`âœ… Enhanced workflow execution completed [Task: ${taskId}, Success: ${finalSuccess}]`);
      return finalSuccess;

    } catch (error) {
      logger.error(`âŒ Enhanced workflow execution failed:`, error);
      
      // ğŸ”§ å‘é€é”™è¯¯äº‹ä»¶
      stream({
        event: 'error',
        data: {
          message: 'Enhanced workflow execution failed',
          details: error instanceof Error ? error.message : String(error)
        }
      });

      await taskExecutorDao.updateTaskStatus(taskId, 'failed');
      return false;
    }
  }
}

// å¯¼å‡ºå•ä¾‹å®ä¾‹
export const enhancedIntelligentTaskService = new EnhancedIntelligentTaskService(); 